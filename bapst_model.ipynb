{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.nn.functional import one_hot\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gcn_model import GCN, GCNNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path, n_graphs=400):\n",
    "    dataset=[]\n",
    "    for i in range(0, n_graphs):\n",
    "        graph = torch.load(data_path+f\"/graph{i}.pt\")\n",
    "        x_oh = one_hot(graph.x.flatten().type(torch.LongTensor), num_classes=2).type(torch.cuda.FloatTensor)\n",
    "        graph.x = x_oh\n",
    "        dataset.append(graph)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"./data/bapst_graphs\", n_graphs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=40, random_state=42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=40, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 training graphs\n",
      "40 validation graphs\n",
      "40 test graphs\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), 'training graphs')\n",
    "print(len(val_dataset), 'validation graphs')\n",
    "print(len(test_dataset), 'test graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GCN([2, 32, 32, 1]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss):\n",
    "    model.train()\n",
    "    loss_acc = 0\n",
    "    total_nodes = 0\n",
    "\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "\n",
    "    for graph_batch in train_loader:\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(graph_batch.x, graph_batch.edge_index)\n",
    "        loss_val = loss(preds.squeeze(), graph_batch.y.squeeze())\n",
    "        loss_acc += loss_val.item()\n",
    "        total_nodes += graph_batch.num_nodes\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_preds.extend(preds.cpu().detach().numpy())\n",
    "        labels.extend(graph_batch.y.cpu().detach().numpy())\n",
    "        \n",
    "    loss_acc /= total_nodes\n",
    "    r2 = r2_score(labels, total_preds)\n",
    "\n",
    "    return loss_acc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, loss):\n",
    "    model.eval()\n",
    "    loss_acc = 0\n",
    "    total_nodes = 0\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for graph_batch in valid_loader:\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            preds = model(graph_batch.x, graph_batch.edge_index)\n",
    "            loss_val = loss(preds.squeeze(), graph_batch.y.squeeze())\n",
    "            loss_acc += loss_val.item()\n",
    "            total_nodes += graph_batch.num_nodes\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            labels.extend(graph_batch.y.cpu().numpy())\n",
    "\n",
    "    r2 = r2_score(labels, total_preds)            \n",
    "    loss_acc /= total_nodes\n",
    "    return loss_acc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.230719006656727e-07\n",
      "Training R2: -0.0016535938304942377\n",
      "Validation Loss: 1.232898466696497e-06\n",
      "Validation R2: -0.0006644309315535502\n",
      "EPOCH: 2\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.23352462728144e-07\n",
      "Training R2: -0.0020422455961428554\n",
      "Validation Loss: 1.238509503309615e-06\n",
      "Validation R2: -0.006400273314388638\n",
      "EPOCH: 3\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.230109360989445e-07\n",
      "Training R2: -0.0015691545679539232\n",
      "Validation Loss: 1.232790691574337e-06\n",
      "Validation R2: -0.0009047525924501532\n",
      "EPOCH: 4\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.22629891924953e-07\n",
      "Training R2: -0.0010413343017054988\n",
      "Validation Loss: 1.2327214790275321e-06\n",
      "Validation R2: -0.000875347558418671\n",
      "EPOCH: 5\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.223870682082633e-07\n",
      "Training R2: -0.0007049498817812694\n",
      "Validation Loss: 1.233758212038083e-06\n",
      "Validation R2: -0.0020289938090833903\n",
      "EPOCH: 6\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.223423949653807e-07\n",
      "Training R2: -0.000643050964043379\n",
      "Validation Loss: 1.2334117400314426e-06\n",
      "Validation R2: -0.0016995286967809164\n",
      "EPOCH: 7\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.222618705782224e-07\n",
      "Training R2: -0.0005315257904421333\n",
      "Validation Loss: 1.2327292097324972e-06\n",
      "Validation R2: -0.0009930393231214474\n",
      "EPOCH: 8\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.220790337214566e-07\n",
      "Training R2: -0.0002782181849643184\n",
      "Validation Loss: 1.2324517683737213e-06\n",
      "Validation R2: -0.0006944628785745532\n",
      "EPOCH: 9\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.221407599899976e-07\n",
      "Training R2: -0.0003637596364984841\n",
      "Validation Loss: 1.2333799077168806e-06\n",
      "Validation R2: -0.0017157525255060424\n",
      "EPOCH: 10\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.220575525934692e-07\n",
      "Training R2: -0.000248470860187755\n",
      "Validation Loss: 1.233194871019805e-06\n",
      "Validation R2: -0.0015418318901394557\n",
      "EPOCH: 11\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.221693067549495e-07\n",
      "Training R2: -0.0004032726632079431\n",
      "Validation Loss: 1.232055501532159e-06\n",
      "Validation R2: -0.0002652813279282462\n",
      "EPOCH: 12\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.222793442451802e-07\n",
      "Training R2: -0.0005557176186297141\n",
      "Validation Loss: 1.2348998097877483e-06\n",
      "Validation R2: -0.0032112439750937583\n",
      "EPOCH: 13\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.223626994345977e-07\n",
      "Training R2: -0.0006711840697672944\n",
      "Validation Loss: 1.2325924217293504e-06\n",
      "Validation R2: -0.0009505811728960367\n",
      "EPOCH: 14\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.219748624720523e-07\n",
      "Training R2: -0.00013393203594880276\n",
      "Validation Loss: 1.2322958809818373e-06\n",
      "Validation R2: -0.0006363748315392215\n",
      "EPOCH: 15\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.220396071261348e-07\n",
      "Training R2: -0.0002236144887532987\n",
      "Validation Loss: 1.2339819477347191e-06\n",
      "Validation R2: -0.0023608308104581255\n",
      "EPOCH: 16\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.219864016860811e-07\n",
      "Training R2: -0.00014991461625801783\n",
      "Validation Loss: 1.2319004781602415e-06\n",
      "Validation R2: -0.00019185628766327234\n",
      "EPOCH: 17\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.219353790333116e-07\n",
      "Training R2: -7.921897288176716e-05\n",
      "Validation Loss: 1.2319420875428476e-06\n",
      "Validation R2: -0.0002755444671165286\n",
      "EPOCH: 18\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.217371091883251e-07\n",
      "Training R2: 0.000195466938400779\n",
      "Validation Loss: 1.2326242540439125e-06\n",
      "Validation R2: -0.0010507459918167594\n",
      "EPOCH: 19\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.219054907636746e-07\n",
      "Training R2: -3.7825724844786635e-05\n",
      "Validation Loss: 1.2325756870268379e-06\n",
      "Validation R2: -0.0010197485810456985\n",
      "EPOCH: 20\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.218269331588089e-07\n",
      "Training R2: 7.100195708575896e-05\n",
      "Validation Loss: 1.2314271316427039e-06\n",
      "Validation R2: 0.00031355264107923997\n",
      "EPOCH: 21\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.216621895622666e-07\n",
      "Training R2: 0.00029922347872080035\n",
      "Validation Loss: 1.237383003171999e-06\n",
      "Validation R2: -0.005531167807965032\n",
      "EPOCH: 22\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.221820965241932e-07\n",
      "Training R2: -0.0004209703692563682\n",
      "Validation Loss: 1.2312921171542257e-06\n",
      "Validation R2: 0.00042316526944496946\n",
      "EPOCH: 23\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.217828567718243e-07\n",
      "Training R2: 0.0001320479415811704\n",
      "Validation Loss: 1.2312626950006233e-06\n",
      "Validation R2: 0.00039644283593442964\n",
      "EPOCH: 24\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.216572726065351e-07\n",
      "Training R2: 0.00030602773136367833\n",
      "Validation Loss: 1.2327936019573825e-06\n",
      "Validation R2: -0.0013124064219254272\n",
      "EPOCH: 25\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.214489016860171e-07\n",
      "Training R2: 0.0005946962293053026\n",
      "Validation Loss: 1.2319339475652668e-06\n",
      "Validation R2: -0.0004687261533675713\n",
      "EPOCH: 26\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.212408092982514e-07\n",
      "Training R2: 0.000882938669428901\n",
      "Validation Loss: 1.2308383247727761e-06\n",
      "Validation R2: 0.0008194670581844754\n",
      "EPOCH: 27\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.215084394829318e-07\n",
      "Training R2: 0.0005122001764821249\n",
      "Validation Loss: 1.2319603229116182e-06\n",
      "Validation R2: -0.0005565279665196154\n",
      "EPOCH: 28\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.216477797555854e-07\n",
      "Training R2: 0.0003191711469929803\n",
      "Validation Loss: 1.2375318874546792e-06\n",
      "Validation R2: -0.005724943128065929\n",
      "EPOCH: 29\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.223698673897161e-07\n",
      "Training R2: -0.0006810957360452452\n",
      "Validation Loss: 1.2345032246230402e-06\n",
      "Validation R2: -0.0030038138709707063\n",
      "EPOCH: 30\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 7.213614139800483e-07\n",
      "Training R2: 0.0007158805848530569\n",
      "Validation Loss: 1.2305556992942002e-06\n",
      "Validation R2: 0.0009216063603406655\n"
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('EPOCH:', epoch+1)\n",
    "    print('Training...')\n",
    "    loss_value, r2_value = train(model, train_dataloader, optimizer, loss)\n",
    "    train_loss.append(loss_value)\n",
    "    train_r2.append(r2_value)\n",
    "\n",
    "    print('Validating..')\n",
    "    loss_value, r2_value = validate(model, val_dataloader, loss)\n",
    "    val_loss.append(loss_value)\n",
    "    val_r2.append(r2_value)\n",
    "\n",
    "\n",
    "    print('Training Loss:', train_loss[-1])\n",
    "    print('Training R2:', train_r2[-1])\n",
    "    print('Validation Loss:', val_loss[-1])\n",
    "    print('Validation R2:', val_r2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.0177],\n",
      "        [-0.0191],\n",
      "        [-0.0180],\n",
      "        ...,\n",
      "        [-0.0193],\n",
      "        [-0.0199],\n",
      "        [-0.0191]], device='cuda:0', grad_fn=<AddBackward0>)\n",
      "torch.Size([131072, 1])\n",
      "torch.Size([131072, 1])\n"
     ]
    }
   ],
   "source": [
    "for batch_graph in train_dataloader:\n",
    "    batch_graph = batch_graph.to(device)\n",
    "    output = model(batch_graph.x, batch_graph.edge_index)\n",
    "    print(output)\n",
    "    print(output.shape)\n",
    "    print(batch_graph.y.shape)\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ter_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
