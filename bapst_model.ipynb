{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/diego/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.nn.functional import one_hot\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from gcn_model import GCN, GCNNet\n",
    "from mpn_model import GraphEncoder, MessageLayer\n",
    "import mpn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(data_path, n_graphs=400):\n",
    "    dataset=[]\n",
    "    for i in range(0, n_graphs):\n",
    "        graph = torch.load(data_path+f\"/graph{i}.pt\")\n",
    "        x_oh = one_hot(graph.x.flatten().type(torch.LongTensor), num_classes=2).type(torch.cuda.FloatTensor)\n",
    "        graph.x = x_oh\n",
    "        dataset.append(graph)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"./data/bapst_graphs\", n_graphs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=40, random_state=42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=40, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 training graphs\n",
      "40 validation graphs\n",
      "40 test graphs\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), 'training graphs')\n",
    "print(len(val_dataset), 'validation graphs')\n",
    "print(len(test_dataset), 'test graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=1, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = mpn_model.PaperGNN(2).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss):\n",
    "    model.train()\n",
    "    loss_acc = 0\n",
    "    total_graphs = 0\n",
    "\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "\n",
    "    for graph_batch in train_loader:\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(graph_batch.x, graph_batch.edge_attr, graph_batch.edge_index)\n",
    "        loss_val = loss(preds.squeeze(), graph_batch.y.squeeze())\n",
    "        loss_acc += loss_val.item()\n",
    "        total_graphs += graph_batch.num_graphs\n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_preds.extend(preds.cpu().detach().numpy())\n",
    "        labels.extend(graph_batch.y.cpu().detach().numpy())\n",
    "        \n",
    "    loss_acc /= total_graphs\n",
    "    r2 = r2_score(labels, total_preds)\n",
    "\n",
    "    return loss_acc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, loss):\n",
    "    model.eval()\n",
    "    loss_acc = 0\n",
    "    total_graphs = 0\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "    with torch.no_grad():\n",
    "        for graph_batch in valid_loader:\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            preds = model(graph_batch.x, graph_batch.edge_attr, graph_batch.edge_index)\n",
    "            loss_val = loss(preds.squeeze(), graph_batch.y.squeeze())\n",
    "            loss_acc += loss_val.item()\n",
    "            total_graphs += graph_batch.num_graphs\n",
    "            total_preds.extend(preds.cpu().numpy())\n",
    "            labels.extend(graph_batch.y.cpu().numpy())\n",
    "\n",
    "    r2 = r2_score(labels, total_preds)            \n",
    "    loss_acc /= total_graphs\n",
    "    return loss_acc, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "loss = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.06197560094296932\n",
      "Training R2: 0.34499155730720077\n",
      "Validation Loss: 0.0642177320085466\n",
      "Validation R2: 0.3755986520333937\n",
      "EPOCH: 2\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.058551107067614794\n",
      "Training R2: 0.3811843876350005\n",
      "Validation Loss: 0.06310237217694521\n",
      "Validation R2: 0.3864435131630667\n",
      "EPOCH: 3\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05783640823792666\n",
      "Training R2: 0.38873790098441763\n",
      "Validation Loss: 0.06818232471123338\n",
      "Validation R2: 0.33705016151151856\n",
      "EPOCH: 4\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05772982182679698\n",
      "Training R2: 0.38986439382768623\n",
      "Validation Loss: 0.06288199173286557\n",
      "Validation R2: 0.3885863154100251\n",
      "EPOCH: 5\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05753598170122132\n",
      "Training R2: 0.3919130537896488\n",
      "Validation Loss: 0.06310829957947135\n",
      "Validation R2: 0.38638587420146386\n",
      "EPOCH: 6\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05760627598501742\n",
      "Training R2: 0.39117012882394375\n",
      "Validation Loss: 0.06699299784377218\n",
      "Validation R2: 0.34861421696165573\n",
      "EPOCH: 7\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05778115491848439\n",
      "Training R2: 0.38932186460165186\n",
      "Validation Loss: 0.0629780956543982\n",
      "Validation R2: 0.3876518806225573\n",
      "EPOCH: 8\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05737099974649027\n",
      "Training R2: 0.39365671613961983\n",
      "Validation Loss: 0.06279223039746284\n",
      "Validation R2: 0.3894590835831345\n",
      "EPOCH: 9\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05719770505093038\n",
      "Training R2: 0.3954882361500561\n",
      "Validation Loss: 0.06452273493632674\n",
      "Validation R2: 0.3726330514868619\n",
      "EPOCH: 10\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.057109959842637184\n",
      "Training R2: 0.39641559895676814\n",
      "Validation Loss: 0.06282297763973474\n",
      "Validation R2: 0.38916012725972204\n",
      "EPOCH: 11\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.0568646922998596\n",
      "Training R2: 0.3990077822498109\n",
      "Validation Loss: 0.06132159000262618\n",
      "Validation R2: 0.40375840624342096\n",
      "EPOCH: 12\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05694782740320079\n",
      "Training R2: 0.39812914462516835\n",
      "Validation Loss: 0.06203421279788017\n",
      "Validation R2: 0.39682943423963424\n",
      "EPOCH: 13\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05634874844690785\n",
      "Training R2: 0.4044606993336015\n",
      "Validation Loss: 0.06133164614439011\n",
      "Validation R2: 0.40366061474706305\n",
      "EPOCH: 14\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.056121477333363146\n",
      "Training R2: 0.4068626844168135\n",
      "Validation Loss: 0.06266694208607078\n",
      "Validation R2: 0.3906772867590048\n",
      "EPOCH: 15\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05629488879349083\n",
      "Training R2: 0.4050299323997938\n",
      "Validation Loss: 0.06198438685387373\n",
      "Validation R2: 0.39731389694254504\n",
      "EPOCH: 16\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05596922143595293\n",
      "Training R2: 0.40847184710416107\n",
      "Validation Loss: 0.06455175941810012\n",
      "Validation R2: 0.3723508467715234\n",
      "EPOCH: 17\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.056089908501598985\n",
      "Training R2: 0.4071963262513748\n",
      "Validation Loss: 0.06382516883313656\n",
      "Validation R2: 0.37941562710573495\n",
      "EPOCH: 18\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05621371828019619\n",
      "Training R2: 0.40588780435496663\n",
      "Validation Loss: 0.060945057030767205\n",
      "Validation R2: 0.40741950579974096\n",
      "EPOCH: 19\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05612825954449363\n",
      "Training R2: 0.40679100197229134\n",
      "Validation Loss: 0.0631535624153912\n",
      "Validation R2: 0.385945780148235\n",
      "EPOCH: 20\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05623374631395563\n",
      "Training R2: 0.405676132350164\n",
      "Validation Loss: 0.06318850256502628\n",
      "Validation R2: 0.3856060473146744\n",
      "EPOCH: 21\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.056197217770386484\n",
      "Training R2: 0.4060621963329826\n",
      "Validation Loss: 0.06314998045563698\n",
      "Validation R2: 0.38598060863372596\n",
      "EPOCH: 22\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.057420082931639624\n",
      "Training R2: 0.393137964324455\n",
      "Validation Loss: 0.062318645883351564\n",
      "Validation R2: 0.3940638346094292\n",
      "EPOCH: 23\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05612508098129183\n",
      "Training R2: 0.40682459687737293\n",
      "Validation Loss: 0.06173213180154562\n",
      "Validation R2: 0.39976662291865217\n",
      "EPOCH: 24\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05586917437613011\n",
      "Training R2: 0.40952922795640867\n",
      "Validation Loss: 0.06118488870561123\n",
      "Validation R2: 0.40508757650834315\n",
      "EPOCH: 25\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.0564324518898502\n",
      "Training R2: 0.40357605080730563\n",
      "Validation Loss: 0.06219876678660512\n",
      "Validation R2: 0.3952294449638303\n",
      "EPOCH: 26\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.055908502219244836\n",
      "Training R2: 0.4091135783782126\n",
      "Validation Loss: 0.061027985997498035\n",
      "Validation R2: 0.40661317517060047\n",
      "EPOCH: 27\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05652969094226137\n",
      "Training R2: 0.40254834952411567\n",
      "Validation Loss: 0.06112232729792595\n",
      "Validation R2: 0.4056958774072319\n",
      "EPOCH: 28\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.05585755207575858\n",
      "Training R2: 0.40965205887228506\n",
      "Validation Loss: 0.06159157957881689\n",
      "Validation R2: 0.4011332412854133\n",
      "EPOCH: 29\n",
      "Training...\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mEPOCH:\u001b[39m\u001b[39m'\u001b[39m, epoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m      8\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTraining...\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m loss_value, r2_value \u001b[39m=\u001b[39m train(model, train_dataloader, optimizer, loss)\n\u001b[1;32m     10\u001b[0m train_loss\u001b[39m.\u001b[39mappend(loss_value)\n\u001b[1;32m     11\u001b[0m train_r2\u001b[39m.\u001b[39mappend(r2_value)\n",
      "Cell \u001b[0;32mIn[10], line 12\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, loss)\u001b[0m\n\u001b[1;32m     10\u001b[0m graph_batch \u001b[39m=\u001b[39m graph_batch\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     11\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 12\u001b[0m preds \u001b[39m=\u001b[39m model(graph_batch\u001b[39m.\u001b[39;49mx, graph_batch\u001b[39m.\u001b[39;49medge_attr, graph_batch\u001b[39m.\u001b[39;49medge_index)\n\u001b[1;32m     13\u001b[0m loss_val \u001b[39m=\u001b[39m loss(preds\u001b[39m.\u001b[39msqueeze(), graph_batch\u001b[39m.\u001b[39my\u001b[39m.\u001b[39msqueeze())\n\u001b[1;32m     14\u001b[0m loss_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m loss_val\u001b[39m.\u001b[39mitem()\n",
      "File \u001b[0;32m~/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Master/M1/TER/TER_GNN/mpn_model.py:129\u001b[0m, in \u001b[0;36mPaperGNN.forward\u001b[0;34m(self, x, edge_features, edge_index)\u001b[0m\n\u001b[1;32m    121\u001b[0m     x \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcatenate([\n\u001b[1;32m    122\u001b[0m         x, x_0\n\u001b[1;32m    123\u001b[0m     ], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    125\u001b[0m     edge_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcatenate([\n\u001b[1;32m    126\u001b[0m         edge_features, e_0\n\u001b[1;32m    127\u001b[0m     ], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m--> 129\u001b[0m     x, edge_features \u001b[39m=\u001b[39m layer(x, edge_features, edge_index)\n\u001b[1;32m    131\u001b[0m x \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnode_decoder(x)\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m x\n",
      "File \u001b[0;32m~/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/Desktop/Master/M1/TER/TER_GNN/mpn_model.py:74\u001b[0m, in \u001b[0;36mMessageLayer.forward\u001b[0;34m(self, x, edge_features, edge_index)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[39m\"\"\"Forward pass for the G step of the DeepMind\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[39mpaper. \u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m    features at step 0\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m\"\"\"\u001b[39;00m        \n\u001b[1;32m     68\u001b[0m extended_edge_features \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mconcat([\n\u001b[1;32m     69\u001b[0m     edge_features, \n\u001b[1;32m     70\u001b[0m     x[edge_index[\u001b[39m0\u001b[39m]], \n\u001b[1;32m     71\u001b[0m     x[edge_index[\u001b[39m1\u001b[39m]]\n\u001b[1;32m     72\u001b[0m ], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpropagate(edge_index, x\u001b[39m=\u001b[39;49mx, edge_features\u001b[39m=\u001b[39;49medge_features)\n\u001b[1;32m     76\u001b[0m edge_features \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39medge_updater_2(extended_edge_features)\n\u001b[1;32m     79\u001b[0m \u001b[39mreturn\u001b[39;00m out, edge_features\n",
      "File \u001b[0;32m~/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:454\u001b[0m, in \u001b[0;36mMessagePassing.propagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    451\u001b[0m     \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    452\u001b[0m         aggr_kwargs \u001b[39m=\u001b[39m res[\u001b[39m0\u001b[39m] \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(res, \u001b[39mtuple\u001b[39m) \u001b[39melse\u001b[39;00m res\n\u001b[0;32m--> 454\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggregate(out, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49maggr_kwargs)\n\u001b[1;32m    456\u001b[0m \u001b[39mfor\u001b[39;00m hook \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_aggregate_forward_hooks\u001b[39m.\u001b[39mvalues():\n\u001b[1;32m    457\u001b[0m     res \u001b[39m=\u001b[39m hook(\u001b[39mself\u001b[39m, (aggr_kwargs, ), out)\n",
      "File \u001b[0;32m~/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/torch_geometric/nn/conv/message_passing.py:578\u001b[0m, in \u001b[0;36mMessagePassing.aggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39maggregate\u001b[39m(\u001b[39mself\u001b[39m, inputs: Tensor, index: Tensor,\n\u001b[1;32m    566\u001b[0m               ptr: Optional[Tensor] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    567\u001b[0m               dim_size: Optional[\u001b[39mint\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[1;32m    568\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Aggregates messages from neighbors as\u001b[39;00m\n\u001b[1;32m    569\u001b[0m \u001b[39m    :math:`\\square_{j \\in \\mathcal{N}(i)}`.\u001b[39;00m\n\u001b[1;32m    570\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[39m    as specified in :meth:`__init__` by the :obj:`aggr` argument.\u001b[39;00m\n\u001b[1;32m    577\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 578\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maggr_module(inputs, index, ptr\u001b[39m=\u001b[39;49mptr, dim_size\u001b[39m=\u001b[39;49mdim_size,\n\u001b[1;32m    579\u001b[0m                             dim\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnode_dim)\n",
      "File \u001b[0;32m~/miniconda3/envs/ter_gnn/lib/python3.10/site-packages/torch_geometric/nn/aggr/base.py:124\u001b[0m, in \u001b[0;36mAggregation.__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    123\u001b[0m     \u001b[39mif\u001b[39;00m dim_size \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 124\u001b[0m         dim_size \u001b[39m=\u001b[39m \u001b[39mint\u001b[39;49m(index\u001b[39m.\u001b[39;49mmax()) \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39melse\u001b[39;00m \u001b[39m0\u001b[39m\n\u001b[1;32m    125\u001b[0m     \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate:\n\u001b[1;32m    126\u001b[0m         \u001b[39mif\u001b[39;00m index\u001b[39m.\u001b[39mnumel() \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m dim_size \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mint\u001b[39m(index\u001b[39m.\u001b[39mmax()):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_loss = []\n",
    "val_loss = []\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "for epoch in range(30):\n",
    "    print('EPOCH:', epoch+1)\n",
    "    print('Training...')\n",
    "    loss_value, r2_value = train(model, train_dataloader, optimizer, loss)\n",
    "    train_loss.append(loss_value)\n",
    "    train_r2.append(r2_value)\n",
    "\n",
    "    print('Validating..')\n",
    "    loss_value, r2_value = validate(model, val_dataloader, loss)\n",
    "    val_loss.append(loss_value)\n",
    "    val_r2.append(r2_value)\n",
    "\n",
    "\n",
    "    print('Training Loss:', train_loss[-1])\n",
    "    print('Training R2:', train_r2[-1])\n",
    "    print('Validation Loss:', val_loss[-1])\n",
    "    print('Validation R2:', val_r2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ter_gnn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
