{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18c42269",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T20:59:45.528243Z",
     "iopub.status.busy": "2023-04-11T20:59:45.527343Z",
     "iopub.status.idle": "2023-04-11T20:59:57.287075Z",
     "shell.execute_reply": "2023-04-11T20:59:57.285661Z"
    },
    "papermill": {
     "duration": 11.769895,
     "end_time": "2023-04-11T20:59:57.289472",
     "exception": false,
     "start_time": "2023-04-11T20:59:45.519577",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in links: file:///kaggle/input/torch-geometric\r\n",
      "Processing /kaggle/input/torch-geometric/torch_scatter-2.1.0-cp37-cp37m-linux_x86_64.whl\r\n",
      "Processing /kaggle/input/torch-geometric/torch_sparse-0.6.16-cp37-cp37m-linux_x86_64.whl\r\n",
      "Processing /kaggle/input/torch-geometric/torch_cluster-1.6.0-cp37-cp37m-linux_x86_64.whl\r\n",
      "Processing /kaggle/input/torch-geometric/torch_spline_conv-1.2.1-cp37-cp37m-linux_x86_64.whl\r\n",
      "Processing /kaggle/input/torch-geometric/torch_geometric-2.2.0-py3-none-any.whl\r\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.7/site-packages (from torch-sparse) (1.7.3)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.21.6)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (3.1.2)\r\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (1.0.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (4.64.1)\r\n",
      "Requirement already satisfied: pyparsing in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (3.0.9)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (2.28.2)\r\n",
      "Requirement already satisfied: psutil>=5.8.0 in /opt/conda/lib/python3.7/site-packages (from torch-geometric) (5.9.3)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.7/site-packages (from jinja2->torch-geometric) (2.1.1)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (3.4)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (2022.12.7)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (2.1.1)\r\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->torch-geometric) (1.26.14)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (3.1.0)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /opt/conda/lib/python3.7/site-packages (from scikit-learn->torch-geometric) (1.2.0)\r\n",
      "Installing collected packages: torch-spline-conv, torch-scatter, torch-cluster, torch-sparse, torch-geometric\r\n",
      "Successfully installed torch-cluster-1.6.0 torch-geometric-2.2.0 torch-scatter-2.1.0 torch-sparse-0.6.16 torch-spline-conv-1.2.1\r\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\r\n",
      "\u001b[0mCPU times: user 164 ms, sys: 19.6 ms, total: 184 ms\n",
      "Wall time: 11.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv torch-geometric --no-index --find-links=file:///kaggle/input/torch-geometric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f55d0027",
   "metadata": {
    "_cell_guid": "39cf968e-a81e-44e1-a505-09d6e8da8c25",
    "_uuid": "994ea2ad-87ac-4e60-bc79-6a7b28ab6ad6",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T20:59:57.303798Z",
     "iopub.status.busy": "2023-04-11T20:59:57.303480Z",
     "iopub.status.idle": "2023-04-11T21:00:11.468260Z",
     "shell.execute_reply": "2023-04-11T21:00:11.467170Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 14.174968,
     "end_time": "2023-04-11T21:00:11.471023",
     "exception": false,
     "start_time": "2023-04-11T20:59:57.296055",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch_geometric as pyg\n",
    "from sklearn.metrics import r2_score\n",
    "from torch.nn.functional import one_hot\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.utils import to_networkx\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, ExponentialLR, StepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import mpn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aedad381",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:11.485263Z",
     "iopub.status.busy": "2023-04-11T21:00:11.484927Z",
     "iopub.status.idle": "2023-04-11T21:00:11.493492Z",
     "shell.execute_reply": "2023-04-11T21:00:11.492548Z"
    },
    "papermill": {
     "duration": 0.017976,
     "end_time": "2023-04-11T21:00:11.495649",
     "exception": false,
     "start_time": "2023-04-11T21:00:11.477673",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed: int):\n",
    "    import random, os\n",
    "    import numpy as np\n",
    "    import torch\n",
    "    \n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e22a726f",
   "metadata": {
    "_cell_guid": "f16560ed-4074-4c6e-9c0f-9edbc65b8f6a",
    "_uuid": "01d99523-820d-420d-b8d6-bc0b990bb5c0",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:11.509528Z",
     "iopub.status.busy": "2023-04-11T21:00:11.508738Z",
     "iopub.status.idle": "2023-04-11T21:00:11.514026Z",
     "shell.execute_reply": "2023-04-11T21:00:11.513090Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014145,
     "end_time": "2023-04-11T21:00:11.516057",
     "exception": false,
     "start_time": "2023-04-11T21:00:11.501912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3d2cfcbc",
   "metadata": {
    "_cell_guid": "3534cfcf-de4a-4c91-bab7-0dae95ca986a",
    "_uuid": "f2bd44a5-11dd-42ea-ba5d-1a19bad6aa4d",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:11.530214Z",
     "iopub.status.busy": "2023-04-11T21:00:11.529361Z",
     "iopub.status.idle": "2023-04-11T21:00:11.536396Z",
     "shell.execute_reply": "2023-04-11T21:00:11.535415Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.016241,
     "end_time": "2023-04-11T21:00:11.538582",
     "exception": false,
     "start_time": "2023-04-11T21:00:11.522341",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def load_dataset(data_path, n_graphs=400):\n",
    "    dataset=[]\n",
    "    for i in range(0, n_graphs):\n",
    "        graph = torch.load(data_path+f\"/graph{i}.pt\")\n",
    "        x_oh = one_hot(graph.x.flatten().type(torch.LongTensor), num_classes=2).type(torch.cuda.FloatTensor)\n",
    "        graph.x = x_oh\n",
    "        dataset.append(graph)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ac93e6d",
   "metadata": {
    "_cell_guid": "1f4df184-5f5f-4995-8492-0ec876d1856c",
    "_uuid": "ed78920f-fa7d-4afe-b058-fce98e38e33e",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:11.552284Z",
     "iopub.status.busy": "2023-04-11T21:00:11.551492Z",
     "iopub.status.idle": "2023-04-11T21:00:42.737587Z",
     "shell.execute_reply": "2023-04-11T21:00:42.736525Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 31.196029,
     "end_time": "2023-04-11T21:00:42.740684",
     "exception": false,
     "start_time": "2023-04-11T21:00:11.544655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset = load_dataset(\"/kaggle/input/bapst-data-static-structure-in-glasses/graphs\", n_graphs=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee028b89",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:42.754770Z",
     "iopub.status.busy": "2023-04-11T21:00:42.754456Z",
     "iopub.status.idle": "2023-04-11T21:00:42.765615Z",
     "shell.execute_reply": "2023-04-11T21:00:42.764611Z"
    },
    "papermill": {
     "duration": 0.020406,
     "end_time": "2023-04-11T21:00:42.767731",
     "exception": false,
     "start_time": "2023-04-11T21:00:42.747325",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Data(x=[4096, 2], edge_index=[2, 167710], edge_attr=[167710, 3], y=[4096, 1], pos=[4096, 3], e_pot=0, pair_pot=0, edge_targets=[167710, 1], delta_r_cage=[4096, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f7ae5b6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:42.781879Z",
     "iopub.status.busy": "2023-04-11T21:00:42.780882Z",
     "iopub.status.idle": "2023-04-11T21:00:42.795133Z",
     "shell.execute_reply": "2023-04-11T21:00:42.794151Z"
    },
    "papermill": {
     "duration": 0.023468,
     "end_time": "2023-04-11T21:00:42.797287",
     "exception": false,
     "start_time": "2023-04-11T21:00:42.773819",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "full_y = np.concatenate([graph.y for graph in dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "48e91d0f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:42.810817Z",
     "iopub.status.busy": "2023-04-11T21:00:42.810537Z",
     "iopub.status.idle": "2023-04-11T21:00:43.111396Z",
     "shell.execute_reply": "2023-04-11T21:00:43.110375Z"
    },
    "papermill": {
     "duration": 0.310073,
     "end_time": "2023-04-11T21:00:43.113513",
     "exception": false,
     "start_time": "2023-04-11T21:00:42.803440",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3.09900e+04, 1.65660e+05, 2.59488e+05, 2.90865e+05, 2.65617e+05,\n",
       "        2.03984e+05, 1.35423e+05, 8.11040e+04, 5.04540e+04, 3.53460e+04,\n",
       "        2.81230e+04, 2.36130e+04, 1.97940e+04, 1.57240e+04, 1.17650e+04,\n",
       "        8.18600e+03, 5.31700e+03, 3.16200e+03, 1.89200e+03, 9.60000e+02,\n",
       "        5.18000e+02, 2.19000e+02, 1.20000e+02, 5.20000e+01, 1.20000e+01,\n",
       "        4.00000e+00, 5.00000e+00, 2.00000e+00, 0.00000e+00, 1.00000e+00]),\n",
       " array([0.09996451, 0.20179093, 0.30361733, 0.40544376, 0.50727016,\n",
       "        0.6090966 , 0.710923  , 0.81274945, 0.9145758 , 1.0164022 ,\n",
       "        1.1182287 , 1.2200551 , 1.3218815 , 1.423708  , 1.5255344 ,\n",
       "        1.6273608 , 1.7291871 , 1.8310136 , 1.93284   , 2.0346665 ,\n",
       "        2.136493  , 2.2383192 , 2.3401456 , 2.441972  , 2.5437984 ,\n",
       "        2.6456249 , 2.7474513 , 2.8492777 , 2.9511042 , 3.0529306 ,\n",
       "        3.154757  ], dtype=float32),\n",
       " <BarContainer object of 30 artists>)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(full_y, bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "27c8576e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.129923Z",
     "iopub.status.busy": "2023-04-11T21:00:43.128135Z",
     "iopub.status.idle": "2023-04-11T21:00:43.141670Z",
     "shell.execute_reply": "2023-04-11T21:00:43.140768Z"
    },
    "papermill": {
     "duration": 0.023605,
     "end_time": "2023-04-11T21:00:43.143819",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.120214",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.59985614, 0.3091052)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_y.mean(), full_y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94e3d891",
   "metadata": {
    "_cell_guid": "ab3117f7-7bd6-46ab-b09a-31ca6c3c14a2",
    "_uuid": "890f5630-9d4a-4cb4-b52f-a4f290e8772c",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.159834Z",
     "iopub.status.busy": "2023-04-11T21:00:43.158922Z",
     "iopub.status.idle": "2023-04-11T21:00:43.166303Z",
     "shell.execute_reply": "2023-04-11T21:00:43.165335Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.017372,
     "end_time": "2023-04-11T21:00:43.168453",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.151081",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataset, test_dataset = train_test_split(dataset, test_size=40, random_state=42)\n",
    "train_dataset, val_dataset = train_test_split(train_dataset, test_size=40, random_state=43)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6bc312f8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.182563Z",
     "iopub.status.busy": "2023-04-11T21:00:43.182295Z",
     "iopub.status.idle": "2023-04-11T21:00:43.191805Z",
     "shell.execute_reply": "2023-04-11T21:00:43.190910Z"
    },
    "papermill": {
     "duration": 0.019014,
     "end_time": "2023-04-11T21:00:43.193930",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.174916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_y = np.concatenate([graph.y for graph in train_dataset], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bf6b62a8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.208563Z",
     "iopub.status.busy": "2023-04-11T21:00:43.207853Z",
     "iopub.status.idle": "2023-04-11T21:00:43.217435Z",
     "shell.execute_reply": "2023-04-11T21:00:43.216543Z"
    },
    "papermill": {
     "duration": 0.018994,
     "end_time": "2023-04-11T21:00:43.219498",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.200504",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_mean = train_y.mean()\n",
    "y_std = train_y.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48b88149",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.233656Z",
     "iopub.status.busy": "2023-04-11T21:00:43.233390Z",
     "iopub.status.idle": "2023-04-11T21:00:43.239084Z",
     "shell.execute_reply": "2023-04-11T21:00:43.238127Z"
    },
    "papermill": {
     "duration": 0.015066,
     "end_time": "2023-04-11T21:00:43.241133",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.226067",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5988441, 0.30760044)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_mean, y_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5b615030",
   "metadata": {
    "_cell_guid": "5dbc7005-2334-42b1-8ec5-ef7a3df3c131",
    "_uuid": "079b32e7-c086-431e-929f-231720ebb407",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.256167Z",
     "iopub.status.busy": "2023-04-11T21:00:43.255416Z",
     "iopub.status.idle": "2023-04-11T21:00:43.261662Z",
     "shell.execute_reply": "2023-04-11T21:00:43.260616Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.015915,
     "end_time": "2023-04-11T21:00:43.263746",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.247831",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320 training graphs\n",
      "40 validation graphs\n",
      "40 test graphs\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset), 'training graphs')\n",
    "print(len(val_dataset), 'validation graphs')\n",
    "print(len(test_dataset), 'test graphs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c682c43",
   "metadata": {
    "_cell_guid": "69f8d2f9-98aa-4190-b8a8-076c02b911dc",
    "_uuid": "af6f70a9-f877-4e8d-8602-447168f3dedf",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.278056Z",
     "iopub.status.busy": "2023-04-11T21:00:43.277774Z",
     "iopub.status.idle": "2023-04-11T21:00:43.282774Z",
     "shell.execute_reply": "2023-04-11T21:00:43.281800Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.014734,
     "end_time": "2023-04-11T21:00:43.285055",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.270321",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset, batch_size=5, shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "34d071ef",
   "metadata": {
    "_cell_guid": "95a64d5b-09a6-452b-a2c2-67287862eeac",
    "_uuid": "115eab64-381d-4cd6-a996-cba2bb4ee25b",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.299502Z",
     "iopub.status.busy": "2023-04-11T21:00:43.299239Z",
     "iopub.status.idle": "2023-04-11T21:00:43.308451Z",
     "shell.execute_reply": "2023-04-11T21:00:43.307381Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018811,
     "end_time": "2023-04-11T21:00:43.310547",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.291736",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, loss):\n",
    "    model.train()\n",
    "    loss_acc = 0\n",
    "    total_a_nodes = 0\n",
    "\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "\n",
    "    for graph_batch in train_loader:\n",
    "        graph_batch = graph_batch.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        preds = model(graph_batch.x, graph_batch.edge_attr, graph_batch.edge_index)\n",
    "        \n",
    "        vector_loss = loss(preds.squeeze(), (graph_batch.y.squeeze() - y_mean)/y_std)\n",
    "        type_a_mask = graph_batch.x[:,0]\n",
    "        loss_val = torch.dot(vector_loss, type_a_mask) \n",
    "        \n",
    "        loss_acc += loss_val.item()\n",
    "        total_a_nodes += graph_batch.x[:, 0].sum().item()\n",
    "        \n",
    "        loss_val.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_preds.extend(y_std*preds[graph_batch.x[:, 0]==1.].cpu().detach().numpy().flatten() + y_mean)\n",
    "        labels.extend(graph_batch.y[graph_batch.x[:, 0]==1.].cpu().detach().numpy().flatten())\n",
    "        \n",
    "    loss_acc /= total_a_nodes\n",
    "#     print(labels[:20], total_preds[:20])\n",
    "    correlation = pearsonr(labels, total_preds)[0]\n",
    "    r2 = r2_score(labels, total_preds)\n",
    "\n",
    "    return loss_acc, correlation, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea0d0372",
   "metadata": {
    "_cell_guid": "5506bde2-ddd5-41de-bf2a-19091eba34ca",
    "_uuid": "09d0d7f9-486d-43ae-b8ab-bfdb54b5c8db",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.324920Z",
     "iopub.status.busy": "2023-04-11T21:00:43.324648Z",
     "iopub.status.idle": "2023-04-11T21:00:43.333933Z",
     "shell.execute_reply": "2023-04-11T21:00:43.333006Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018864,
     "end_time": "2023-04-11T21:00:43.336069",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.317205",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def validate(model, valid_loader, loss):\n",
    "    model.eval()\n",
    "    loss_acc = 0\n",
    "    total_a_nodes = 0\n",
    "    total_preds = []\n",
    "    labels = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for graph_batch in valid_loader:\n",
    "            graph_batch = graph_batch.to(device)\n",
    "            preds = model(graph_batch.x, graph_batch.edge_attr, graph_batch.edge_index)\n",
    "            \n",
    "            vector_loss = loss(preds.squeeze(), (graph_batch.y.squeeze() - y_mean)/y_std)\n",
    "            type_a_mask = graph_batch.x[:,0]\n",
    "            loss_val = torch.dot(vector_loss, type_a_mask)\n",
    "            loss_acc += loss_val.item()\n",
    "            \n",
    "            total_a_nodes += graph_batch.x[:, 0].sum().item()\n",
    "            total_preds.extend(y_std*preds[graph_batch.x[:, 0]==1.].cpu().detach().numpy().flatten() + y_mean)\n",
    "            labels.extend(graph_batch.y[graph_batch.x[:, 0]==1.].cpu().detach().numpy().flatten())\n",
    "\n",
    "    loss_acc /= total_a_nodes\n",
    "    if len(set(total_preds)) == 1:\n",
    "        raise Exception('Constant prediction')\n",
    "    correlation = pearsonr(labels, total_preds)[0]            \n",
    "    r2 = r2_score(labels, total_preds)\n",
    "\n",
    "    return loss_acc, correlation, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6aa107c1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.350648Z",
     "iopub.status.busy": "2023-04-11T21:00:43.350389Z",
     "iopub.status.idle": "2023-04-11T21:00:43.373421Z",
     "shell.execute_reply": "2023-04-11T21:00:43.372492Z"
    },
    "papermill": {
     "duration": 0.032888,
     "end_time": "2023-04-11T21:00:43.375595",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.342707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = mpn_model.PaperGNN(7).to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c226653f",
   "metadata": {
    "_cell_guid": "ef6774f3-e3af-4894-bd27-42a17ea3c0d3",
    "_uuid": "4aedf625-f0e1-4520-9497-0cd014ac1fe8",
    "collapsed": false,
    "execution": {
     "iopub.execute_input": "2023-04-11T21:00:43.446696Z",
     "iopub.status.busy": "2023-04-11T21:00:43.446435Z",
     "iopub.status.idle": "2023-04-12T01:14:38.308525Z",
     "shell.execute_reply": "2023-04-12T01:14:38.304990Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 15234.873711,
     "end_time": "2023-04-12T01:14:38.312435",
     "exception": false,
     "start_time": "2023-04-11T21:00:43.438724",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH: 1\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23627539836381825\n",
      "Training correlation: 0.5827803998480864\n",
      "Training r2: 0.33962634331806396\n",
      "Validation Loss: 0.2659303638969284\n",
      "Validation correlation: 0.5787953595506333\n",
      "Validation r2: 0.3331690078478565\n",
      "EPOCH: 2\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2360328229637018\n",
      "Training correlation: 0.5833879694208879\n",
      "Training r2: 0.34030432193045446\n",
      "Validation Loss: 0.26780317467743936\n",
      "Validation correlation: 0.5787571453795902\n",
      "Validation r2: 0.3284728741040781\n",
      "EPOCH: 3\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23583329997849894\n",
      "Training correlation: 0.5838410233039903\n",
      "Training r2: 0.34086197635383464\n",
      "Validation Loss: 0.2682732999706763\n",
      "Validation correlation: 0.5788260019538558\n",
      "Validation r2: 0.32729400906037887\n",
      "EPOCH: 4\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23578586176760793\n",
      "Training correlation: 0.5839857992294667\n",
      "Training r2: 0.34099456000818107\n",
      "Validation Loss: 0.26592357124465976\n",
      "Validation correlation: 0.5789568018202742\n",
      "Validation r2: 0.3331860487118721\n",
      "EPOCH: 5\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23596405387834182\n",
      "Training correlation: 0.5835791250659673\n",
      "Training r2: 0.3404965248111792\n",
      "Validation Loss: 0.26557345444158625\n",
      "Validation correlation: 0.5790013071588094\n",
      "Validation r2: 0.3340639661887067\n",
      "EPOCH: 6\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23558555279412502\n",
      "Training correlation: 0.5844335997232268\n",
      "Training r2: 0.3415544163330472\n",
      "Validation Loss: 0.26740817272848644\n",
      "Validation correlation: 0.5788998508376493\n",
      "Validation r2: 0.32946335151047557\n",
      "EPOCH: 7\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.235864106947451\n",
      "Training correlation: 0.5837740212201135\n",
      "Training r2: 0.34077586717275987\n",
      "Validation Loss: 0.26807111659208593\n",
      "Validation correlation: 0.5788998761968803\n",
      "Validation r2: 0.32780099049182\n",
      "EPOCH: 8\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.236000376035791\n",
      "Training correlation: 0.5834469335283193\n",
      "Training r2: 0.34039500904636444\n",
      "Validation Loss: 0.26681224833474787\n",
      "Validation correlation: 0.5789299894228059\n",
      "Validation r2: 0.3309576520557348\n",
      "EPOCH: 9\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23589269051946152\n",
      "Training correlation: 0.5836944845278278\n",
      "Training r2: 0.3406959863094675\n",
      "Validation Loss: 0.26737360414441563\n",
      "Validation correlation: 0.5789786353912467\n",
      "Validation r2: 0.3295500324927545\n",
      "EPOCH: 10\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23578230829038088\n",
      "Training correlation: 0.5839786191162017\n",
      "Training r2: 0.341004498898956\n",
      "Validation Loss: 0.26655397482095855\n",
      "Validation correlation: 0.5790472438636225\n",
      "Validation r2: 0.33160529401828465\n",
      "EPOCH: 11\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23574803119248502\n",
      "Training correlation: 0.5840642911931423\n",
      "Training r2: 0.34110029728792446\n",
      "Validation Loss: 0.2664468420108426\n",
      "Validation correlation: 0.5790205991867929\n",
      "Validation r2: 0.33187392243596825\n",
      "EPOCH: 12\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23595971464565116\n",
      "Training correlation: 0.5835423695419057\n",
      "Training r2: 0.34050865287466425\n",
      "Validation Loss: 0.26540160797556833\n",
      "Validation correlation: 0.5791260616284106\n",
      "Validation r2: 0.3344948754932763\n",
      "EPOCH: 13\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23578496682123692\n",
      "Training correlation: 0.5839622689304752\n",
      "Training r2: 0.34099706428044196\n",
      "Validation Loss: 0.2660881314875696\n",
      "Validation correlation: 0.5790471823031048\n",
      "Validation r2: 0.3327734129379669\n",
      "EPOCH: 14\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23573174707984867\n",
      "Training correlation: 0.5841085150840112\n",
      "Training r2: 0.34114580888259294\n",
      "Validation Loss: 0.2654816241900223\n",
      "Validation correlation: 0.5791298493926396\n",
      "Validation r2: 0.3342942503530717\n",
      "EPOCH: 15\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23589657762263802\n",
      "Training correlation: 0.583688950042276\n",
      "Training r2: 0.34068511540639734\n",
      "Validation Loss: 0.2661857076487164\n",
      "Validation correlation: 0.5790869477328852\n",
      "Validation r2: 0.3325287257892082\n",
      "EPOCH: 16\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23569664837275842\n",
      "Training correlation: 0.5841886667930447\n",
      "Training r2: 0.34124391282012245\n",
      "Validation Loss: 0.26654444238489855\n",
      "Validation correlation: 0.5790953021981502\n",
      "Validation r2: 0.33162918286402976\n",
      "EPOCH: 17\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23578979939195052\n",
      "Training correlation: 0.5839531407024339\n",
      "Training r2: 0.340983552427508\n",
      "Validation Loss: 0.266567794804461\n",
      "Validation correlation: 0.5791298673182628\n",
      "Validation r2: 0.3315706235061191\n",
      "EPOCH: 18\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23563835625972987\n",
      "Training correlation: 0.584317105595328\n",
      "Training r2: 0.3414068290770411\n",
      "Validation Loss: 0.26549047493956457\n",
      "Validation correlation: 0.5791334012330696\n",
      "Validation r2: 0.3342720635203299\n",
      "EPOCH: 19\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2361035439820416\n",
      "Training correlation: 0.583208094767077\n",
      "Training r2: 0.3401066619013686\n",
      "Validation Loss: 0.265785544625062\n",
      "Validation correlation: 0.5791621122163385\n",
      "Validation r2: 0.3335321768405236\n",
      "EPOCH: 20\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23586403593843872\n",
      "Training correlation: 0.5837788919228597\n",
      "Training r2: 0.34077607508277674\n",
      "Validation Loss: 0.26620281500026227\n",
      "Validation correlation: 0.5791569203069195\n",
      "Validation r2: 0.3324858260761864\n",
      "EPOCH: 21\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2357420797059912\n",
      "Training correlation: 0.5840578892482988\n",
      "Training r2: 0.3411169266636598\n",
      "Validation Loss: 0.26547508670456493\n",
      "Validation correlation: 0.5792232445408584\n",
      "Validation r2: 0.334310627679101\n",
      "EPOCH: 22\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23585002574390998\n",
      "Training correlation: 0.5838162117184367\n",
      "Training r2: 0.3408152225352392\n",
      "Validation Loss: 0.265608237216776\n",
      "Validation correlation: 0.5792162088305752\n",
      "Validation r2: 0.33397677354639055\n",
      "EPOCH: 23\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23572507805310627\n",
      "Training correlation: 0.5840943012718929\n",
      "Training r2: 0.3411644449993694\n",
      "Validation Loss: 0.2673592552019759\n",
      "Validation correlation: 0.5791088495706431\n",
      "Validation r2: 0.32958602355992694\n",
      "EPOCH: 24\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23566767366913932\n",
      "Training correlation: 0.5842328446304671\n",
      "Training r2: 0.34132487923088806\n",
      "Validation Loss: 0.26847796796624673\n",
      "Validation correlation: 0.5790866641558272\n",
      "Validation r2: 0.32678079812105876\n",
      "EPOCH: 25\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23607545607621835\n",
      "Training correlation: 0.5832573441685105\n",
      "Training r2: 0.34018516604923466\n",
      "Validation Loss: 0.2662832819473318\n",
      "Validation correlation: 0.5792370079197579\n",
      "Validation r2: 0.33228405295057095\n",
      "EPOCH: 26\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23574432871274043\n",
      "Training correlation: 0.5840606879574182\n",
      "Training r2: 0.3411106455285411\n",
      "Validation Loss: 0.26593324150804853\n",
      "Validation correlation: 0.5792297601782699\n",
      "Validation r2: 0.33316178326196055\n",
      "EPOCH: 27\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23592275946031885\n",
      "Training correlation: 0.5837074497886912\n",
      "Training r2: 0.34061194648605164\n",
      "Validation Loss: 0.26601037452378795\n",
      "Validation correlation: 0.5792395169174058\n",
      "Validation r2: 0.33296838408487295\n",
      "EPOCH: 28\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2359934814099244\n",
      "Training correlation: 0.5835048228268163\n",
      "Training r2: 0.34041427558548654\n",
      "Validation Loss: 0.2652108493650109\n",
      "Validation correlation: 0.5792494228456178\n",
      "Validation r2: 0.3349732339956034\n",
      "EPOCH: 29\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23598777438068594\n",
      "Training correlation: 0.5834778237967594\n",
      "Training r2: 0.34043022567121073\n",
      "Validation Loss: 0.2669054866601026\n",
      "Validation correlation: 0.5792312320010591\n",
      "Validation r2: 0.33072385199960375\n",
      "EPOCH: 30\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23572245281500026\n",
      "Training correlation: 0.5841084372489287\n",
      "Training r2: 0.34117178544295823\n",
      "Validation Loss: 0.2663191002900185\n",
      "Validation correlation: 0.579285259060768\n",
      "Validation r2: 0.33219424042522816\n",
      "EPOCH: 31\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23574983272604874\n",
      "Training correlation: 0.5840397888527304\n",
      "Training r2: 0.3410952597402973\n",
      "Validation Loss: 0.26598168595156585\n",
      "Validation correlation: 0.5792585945691422\n",
      "Validation r2: 0.3330403287849226\n",
      "EPOCH: 32\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23564111117658945\n",
      "Training correlation: 0.584300382118667\n",
      "Training r2: 0.34139912828479246\n",
      "Validation Loss: 0.2651109953278771\n",
      "Validation correlation: 0.5793578868590314\n",
      "Validation r2: 0.3352236112854362\n",
      "EPOCH: 33\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23577976104578013\n",
      "Training correlation: 0.5839750435892217\n",
      "Training r2: 0.34101161238267697\n",
      "Validation Loss: 0.2663153286637931\n",
      "Validation correlation: 0.579262925281895\n",
      "Validation r2: 0.33220371005332416\n",
      "EPOCH: 34\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23552738989421715\n",
      "Training correlation: 0.5845770312048089\n",
      "Training r2: 0.3417169755649392\n",
      "Validation Loss: 0.265581668205366\n",
      "Validation correlation: 0.5792633845413849\n",
      "Validation r2: 0.33404336783031163\n",
      "EPOCH: 35\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23576443171333822\n",
      "Training correlation: 0.5839997750822091\n",
      "Training r2: 0.3410544605840642\n",
      "Validation Loss: 0.26545642972683664\n",
      "Validation correlation: 0.5793487878584498\n",
      "Validation r2: 0.33435743640801263\n",
      "EPOCH: 36\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23568093279785304\n",
      "Training correlation: 0.5842178453439493\n",
      "Training r2: 0.3412878330854813\n",
      "Validation Loss: 0.2672429401117161\n",
      "Validation correlation: 0.5792221379150004\n",
      "Validation r2: 0.3298776810404106\n",
      "EPOCH: 37\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2356968399806833\n",
      "Training correlation: 0.5841705925513246\n",
      "Training r2: 0.34124336483604234\n",
      "Validation Loss: 0.26561102170132267\n",
      "Validation correlation: 0.5793220733688773\n",
      "Validation r2: 0.33396979433928586\n",
      "EPOCH: 38\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2355239339670758\n",
      "Training correlation: 0.5845772190547212\n",
      "Training r2: 0.3417266383463087\n",
      "Validation Loss: 0.26697911997921114\n",
      "Validation correlation: 0.5792788768095739\n",
      "Validation r2: 0.3305392286747011\n",
      "EPOCH: 39\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2356860810676507\n",
      "Training correlation: 0.5842386360790777\n",
      "Training r2: 0.34127344914540836\n",
      "Validation Loss: 0.26512795367690534\n",
      "Validation correlation: 0.5794146812824021\n",
      "Validation r2: 0.3351810969882262\n",
      "EPOCH: 40\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23567810431100045\n",
      "Training correlation: 0.5842270017139656\n",
      "Training r2: 0.34129573309007166\n",
      "Validation Loss: 0.26615773242604707\n",
      "Validation correlation: 0.579349353722062\n",
      "Validation r2: 0.3325988728847773\n",
      "EPOCH: 41\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23560336232003476\n",
      "Training correlation: 0.5843989494667994\n",
      "Training r2: 0.34150463293681066\n",
      "Validation Loss: 0.26595660882786276\n",
      "Validation correlation: 0.5793338574259047\n",
      "Validation r2: 0.3331031806152558\n",
      "EPOCH: 42\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23563635916036188\n",
      "Training correlation: 0.5843191476402876\n",
      "Training r2: 0.3414124090802555\n",
      "Validation Loss: 0.26524894558368456\n",
      "Validation correlation: 0.5794061440325747\n",
      "Validation r2: 0.3348777012487466\n",
      "EPOCH: 43\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23557200148078702\n",
      "Training correlation: 0.5844723083744379\n",
      "Training r2: 0.34159229052211737\n",
      "Validation Loss: 0.2651422765439045\n",
      "Validation correlation: 0.5794756671416093\n",
      "Validation r2: 0.33514516831250474\n",
      "EPOCH: 44\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23594658915357034\n",
      "Training correlation: 0.5835662019913872\n",
      "Training r2: 0.34054533785705754\n",
      "Validation Loss: 0.2672899410933447\n",
      "Validation correlation: 0.579336671760772\n",
      "Validation r2: 0.3297598143155982\n",
      "EPOCH: 45\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2357102786108674\n",
      "Training correlation: 0.5841301771556172\n",
      "Training r2: 0.34120581073740375\n",
      "Validation Loss: 0.2654679494839745\n",
      "Validation correlation: 0.579450601294837\n",
      "Validation r2: 0.334328544410221\n",
      "EPOCH: 46\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23576380869656174\n",
      "Training correlation: 0.5840641077489876\n",
      "Training r2: 0.34105620142597226\n",
      "Validation Loss: 0.26753895596319993\n",
      "Validation correlation: 0.5792374627403902\n",
      "Validation r2: 0.32913541989116213\n",
      "EPOCH: 47\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2357401016975708\n",
      "Training correlation: 0.5840646636313296\n",
      "Training r2: 0.34112245881447933\n",
      "Validation Loss: 0.2668185008528904\n",
      "Validation correlation: 0.5793699318588432\n",
      "Validation r2: 0.330941966814166\n",
      "EPOCH: 48\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2358666788705937\n",
      "Training correlation: 0.5838080593730284\n",
      "Training r2: 0.3407686847528245\n",
      "Validation Loss: 0.2653919526124313\n",
      "Validation correlation: 0.5794699370396359\n",
      "Validation r2: 0.33451909609659247\n",
      "EPOCH: 49\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23575271359659894\n",
      "Training correlation: 0.5840406105209004\n",
      "Training r2: 0.34108720112768154\n",
      "Validation Loss: 0.2652934135225149\n",
      "Validation correlation: 0.5794992308535698\n",
      "Validation r2: 0.3347661903077328\n",
      "EPOCH: 50\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23577454828583033\n",
      "Training correlation: 0.5839795045088865\n",
      "Training r2: 0.3410261826015559\n",
      "Validation Loss: 0.26512203827695874\n",
      "Validation correlation: 0.5795095537417443\n",
      "Validation r2: 0.33519593855291474\n",
      "EPOCH: 51\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23558737458271845\n",
      "Training correlation: 0.5844382699170514\n",
      "Training r2: 0.34154932320024334\n",
      "Validation Loss: 0.2661810084818193\n",
      "Validation correlation: 0.5794410322128398\n",
      "Validation r2: 0.33254052557692415\n",
      "EPOCH: 52\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23573884379037968\n",
      "Training correlation: 0.5840653187206354\n",
      "Training r2: 0.34112597664087285\n",
      "Validation Loss: 0.2651566478367218\n",
      "Validation correlation: 0.5795219666843006\n",
      "Validation r2: 0.33510914084572885\n",
      "EPOCH: 53\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2355559085104427\n",
      "Training correlation: 0.5845012404353681\n",
      "Training r2: 0.3416372680868136\n",
      "Validation Loss: 0.26582732493098205\n",
      "Validation correlation: 0.5794608020089462\n",
      "Validation r2: 0.3334273854200944\n",
      "EPOCH: 54\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23577190046453025\n",
      "Training correlation: 0.5840350695202373\n",
      "Training r2: 0.34103358309895926\n",
      "Validation Loss: 0.26556630045821256\n",
      "Validation correlation: 0.5794825081011044\n",
      "Validation r2: 0.33408191872562465\n",
      "EPOCH: 55\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23567770340110167\n",
      "Training correlation: 0.5843311360513408\n",
      "Training r2: 0.3412968592620238\n",
      "Validation Loss: 0.26580310270922336\n",
      "Validation correlation: 0.5794781871710688\n",
      "Validation r2: 0.3334881044691991\n",
      "EPOCH: 56\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23592701930260565\n",
      "Training correlation: 0.583628246393786\n",
      "Training r2: 0.3406000421142301\n",
      "Validation Loss: 0.2662715535866694\n",
      "Validation correlation: 0.5794581377266002\n",
      "Validation r2: 0.3323134649390129\n",
      "EPOCH: 57\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23547447490954057\n",
      "Training correlation: 0.5846953386865155\n",
      "Training r2: 0.3418648705288092\n",
      "Validation Loss: 0.266535185603496\n",
      "Validation correlation: 0.5794878379551178\n",
      "Validation r2: 0.3316524033845136\n",
      "EPOCH: 58\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542378844376705\n",
      "Training correlation: 0.5848235981099692\n",
      "Training r2: 0.3420065341339098\n",
      "Validation Loss: 0.2655985073523802\n",
      "Validation correlation: 0.5795600519297377\n",
      "Validation r2: 0.33400115817996323\n",
      "EPOCH: 59\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23551882178382536\n",
      "Training correlation: 0.5845886107912062\n",
      "Training r2: 0.34174091823926533\n",
      "Validation Loss: 0.2657018703988023\n",
      "Validation correlation: 0.5795342409872046\n",
      "Validation r2: 0.33374194687243397\n",
      "EPOCH: 60\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23556339984482877\n",
      "Training correlation: 0.5844951242997057\n",
      "Training r2: 0.34161632549093235\n",
      "Validation Loss: 0.2663819625896399\n",
      "Validation correlation: 0.5794971616518099\n",
      "Validation r2: 0.3320366214549152\n",
      "EPOCH: 61\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23561735575178028\n",
      "Training correlation: 0.5844522538574652\n",
      "Training r2: 0.34146552823276455\n",
      "Validation Loss: 0.265294314987746\n",
      "Validation correlation: 0.5795262180438381\n",
      "Validation r2: 0.3347639393077917\n",
      "EPOCH: 62\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23571816596600717\n",
      "Training correlation: 0.5841602798571008\n",
      "Training r2: 0.34118376547332474\n",
      "Validation Loss: 0.2653992798112317\n",
      "Validation correlation: 0.5795992977989096\n",
      "Validation r2: 0.3345007438474846\n",
      "EPOCH: 63\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23546725736728047\n",
      "Training correlation: 0.5847119420327747\n",
      "Training r2: 0.3418850375518766\n",
      "Validation Loss: 0.2653130166662296\n",
      "Validation correlation: 0.579608006658483\n",
      "Validation r2: 0.33471704724138596\n",
      "EPOCH: 64\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23570245434898118\n",
      "Training correlation: 0.5842035666309254\n",
      "Training r2: 0.3412276830980594\n",
      "Validation Loss: 0.266062389440132\n",
      "Validation correlation: 0.5795472351914925\n",
      "Validation r2: 0.3328379578037418\n",
      "EPOCH: 65\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23569780430635157\n",
      "Training correlation: 0.5841747646478306\n",
      "Training r2: 0.3412406759701637\n",
      "Validation Loss: 0.2671580198519034\n",
      "Validation correlation: 0.5795179622516593\n",
      "Validation r2: 0.3300905976276518\n",
      "EPOCH: 66\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2355184043439598\n",
      "Training correlation: 0.5845961333404993\n",
      "Training r2: 0.34174208402204587\n",
      "Validation Loss: 0.2666090685018214\n",
      "Validation correlation: 0.5795523713427898\n",
      "Validation r2: 0.3314671448850961\n",
      "EPOCH: 67\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23576254962528848\n",
      "Training correlation: 0.5840114384983379\n",
      "Training r2: 0.3410597168788866\n",
      "Validation Loss: 0.265487412937829\n",
      "Validation correlation: 0.5796442922992451\n",
      "Validation r2: 0.33427973541230327\n",
      "EPOCH: 68\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23573237428732097\n",
      "Training correlation: 0.5840802385098574\n",
      "Training r2: 0.3411440543874684\n",
      "Validation Loss: 0.26555146353252784\n",
      "Validation correlation: 0.5795817506907144\n",
      "Validation r2: 0.33411912393548926\n",
      "EPOCH: 69\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23561239839145823\n",
      "Training correlation: 0.584369843255975\n",
      "Training r2: 0.3414793798252145\n",
      "Validation Loss: 0.2652208250835606\n",
      "Validation correlation: 0.5795978076492136\n",
      "Validation r2: 0.33494822672694236\n",
      "EPOCH: 70\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2355089296463753\n",
      "Training correlation: 0.5846226010926874\n",
      "Training r2: 0.3417685668918228\n",
      "Validation Loss: 0.2658400981717987\n",
      "Validation correlation: 0.5796179688503242\n",
      "Validation r2: 0.3333953633407861\n",
      "EPOCH: 71\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23544871144299104\n",
      "Training correlation: 0.5847630486182964\n",
      "Training r2: 0.34193687963409036\n",
      "Validation Loss: 0.26600124066946235\n",
      "Validation correlation: 0.5795747945860668\n",
      "Validation r2: 0.3329912966921543\n",
      "EPOCH: 72\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2356548198738366\n",
      "Training correlation: 0.5842627533133586\n",
      "Training r2: 0.3413608151237737\n",
      "Validation Loss: 0.26586196429124864\n",
      "Validation correlation: 0.5796170359016544\n",
      "Validation r2: 0.33334052547762016\n",
      "EPOCH: 73\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23538540492961418\n",
      "Training correlation: 0.5849158811287634\n",
      "Training r2: 0.3421138090636072\n",
      "Validation Loss: 0.2674695543155897\n",
      "Validation correlation: 0.5795460632847094\n",
      "Validation r2: 0.32930944389800143\n",
      "EPOCH: 74\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2356152252485958\n",
      "Training correlation: 0.5844200286173489\n",
      "Training r2: 0.3414714809663715\n",
      "Validation Loss: 0.2658628806567316\n",
      "Validation correlation: 0.5796459617909855\n",
      "Validation r2: 0.3333382414795063\n",
      "EPOCH: 75\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542611008924358\n",
      "Training correlation: 0.5848433520119096\n",
      "Training r2: 0.34200004955258123\n",
      "Validation Loss: 0.26595717503742944\n",
      "Validation correlation: 0.5796570419276509\n",
      "Validation r2: 0.3331018109593685\n",
      "EPOCH: 76\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.235692667910192\n",
      "Training correlation: 0.5841745885529657\n",
      "Training r2: 0.3412550336201192\n",
      "Validation Loss: 0.26559131425584565\n",
      "Validation correlation: 0.5796986983268242\n",
      "Validation r2: 0.3340192025157812\n",
      "EPOCH: 77\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23571242680810084\n",
      "Training correlation: 0.5841293376518031\n",
      "Training r2: 0.3411998038444761\n",
      "Validation Loss: 0.2656396730229154\n",
      "Validation correlation: 0.5796767967161427\n",
      "Validation r2: 0.3338979490950891\n",
      "EPOCH: 78\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23561902504560966\n",
      "Training correlation: 0.5843487109027662\n",
      "Training r2: 0.34146085819050265\n",
      "Validation Loss: 0.2651881525565256\n",
      "Validation correlation: 0.5796848163058047\n",
      "Validation r2: 0.33503013749731547\n",
      "EPOCH: 79\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23559161440279194\n",
      "Training correlation: 0.5844281139895722\n",
      "Training r2: 0.34153746915980043\n",
      "Validation Loss: 0.26544043430657804\n",
      "Validation correlation: 0.579740857368802\n",
      "Validation r2: 0.3343975265023137\n",
      "EPOCH: 80\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2353766875838884\n",
      "Training correlation: 0.5849323578866799\n",
      "Training r2: 0.34213817346314257\n",
      "Validation Loss: 0.26535435927725437\n",
      "Validation correlation: 0.5797644973690712\n",
      "Validation r2: 0.33461336413391907\n",
      "EPOCH: 81\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2355759991717695\n",
      "Training correlation: 0.5844511437044657\n",
      "Training r2: 0.3415811142030125\n",
      "Validation Loss: 0.26608339693257455\n",
      "Validation correlation: 0.5797405115455627\n",
      "Validation r2: 0.33278527146421666\n",
      "EPOCH: 82\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23603023427777586\n",
      "Training correlation: 0.5833632062098006\n",
      "Training r2: 0.3403115526792241\n",
      "Validation Loss: 0.2663055503735791\n",
      "Validation correlation: 0.5797569347771976\n",
      "Validation r2: 0.33222822009560193\n",
      "EPOCH: 83\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354749107419044\n",
      "Training correlation: 0.5847016600700401\n",
      "Training r2: 0.34186365622778114\n",
      "Validation Loss: 0.2651122860621853\n",
      "Validation correlation: 0.5798006376444215\n",
      "Validation r2: 0.33522039143139015\n",
      "EPOCH: 84\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23616082357640014\n",
      "Training correlation: 0.5830596627800065\n",
      "Training r2: 0.33994656678671664\n",
      "Validation Loss: 0.26815514842438776\n",
      "Validation correlation: 0.5796334632029967\n",
      "Validation r2: 0.32759027551869824\n",
      "EPOCH: 85\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23549365991494042\n",
      "Training correlation: 0.5846681034793286\n",
      "Training r2: 0.3418112448078534\n",
      "Validation Loss: 0.2657684577613623\n",
      "Validation correlation: 0.5797756141467324\n",
      "Validation r2: 0.3335749985601145\n",
      "EPOCH: 86\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354220986620915\n",
      "Training correlation: 0.5848202966080369\n",
      "Training r2: 0.34201125433037416\n",
      "Validation Loss: 0.26618426046176474\n",
      "Validation correlation: 0.5797712078041475\n",
      "Validation r2: 0.33253235612134024\n",
      "EPOCH: 87\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23581480271284413\n",
      "Training correlation: 0.5838841038401901\n",
      "Training r2: 0.34091367395594707\n",
      "Validation Loss: 0.2657042972773068\n",
      "Validation correlation: 0.5798163787314695\n",
      "Validation r2: 0.3337358963124073\n",
      "EPOCH: 88\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23538631826848347\n",
      "Training correlation: 0.5849129324262331\n",
      "Training r2: 0.3421112588629226\n",
      "Validation Loss: 0.26647598690327473\n",
      "Validation correlation: 0.5797721087875121\n",
      "Validation r2: 0.3318008293845143\n",
      "EPOCH: 89\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23561668756861565\n",
      "Training correlation: 0.5843581707659193\n",
      "Training r2: 0.3414673909996513\n",
      "Validation Loss: 0.26615177418787667\n",
      "Validation correlation: 0.5798048620845824\n",
      "Validation r2: 0.33261380527929885\n",
      "EPOCH: 90\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23562333471061328\n",
      "Training correlation: 0.5843373901155196\n",
      "Training r2: 0.34144881251820725\n",
      "Validation Loss: 0.26780414691886634\n",
      "Validation correlation: 0.5797264835480025\n",
      "Validation r2: 0.3284704284940959\n",
      "EPOCH: 91\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2353351156486765\n",
      "Training correlation: 0.585039748395515\n",
      "Training r2: 0.3422543590077266\n",
      "Validation Loss: 0.26558332213331076\n",
      "Validation correlation: 0.5798434976322608\n",
      "Validation r2: 0.3340392398983547\n",
      "EPOCH: 92\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23539696519681147\n",
      "Training correlation: 0.5848783939344714\n",
      "Training r2: 0.3420814996346383\n",
      "Validation Loss: 0.2655655479954989\n",
      "Validation correlation: 0.5797875827988426\n",
      "Validation r2: 0.33408381754355776\n",
      "EPOCH: 93\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23547811708982885\n",
      "Training correlation: 0.5846973090542187\n",
      "Training r2: 0.3418546868100467\n",
      "Validation Loss: 0.2667900190216614\n",
      "Validation correlation: 0.5797654712880549\n",
      "Validation r2: 0.3310134060770491\n",
      "EPOCH: 94\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23539185324637746\n",
      "Training correlation: 0.5849093345419005\n",
      "Training r2: 0.3420957848127212\n",
      "Validation Loss: 0.2652888968837018\n",
      "Validation correlation: 0.5798800409257245\n",
      "Validation r2: 0.33477753283333567\n",
      "EPOCH: 95\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354797915056198\n",
      "Training correlation: 0.5846836081200989\n",
      "Training r2: 0.34185001337975385\n",
      "Validation Loss: 0.264907424363342\n",
      "Validation correlation: 0.579863152342752\n",
      "Validation r2: 0.3357340777764769\n",
      "EPOCH: 96\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23543728085454732\n",
      "Training correlation: 0.5847884675792777\n",
      "Training r2: 0.3419688209678934\n",
      "Validation Loss: 0.2664751618018338\n",
      "Validation correlation: 0.5797766110050359\n",
      "Validation r2: 0.3318029085038354\n",
      "EPOCH: 97\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354273745152948\n",
      "Training correlation: 0.5848049586690593\n",
      "Training r2: 0.3419965054497506\n",
      "Validation Loss: 0.26720092326429945\n",
      "Validation correlation: 0.579772325572024\n",
      "Validation r2: 0.32998304988871807\n",
      "EPOCH: 98\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23581162127627808\n",
      "Training correlation: 0.5839021752667433\n",
      "Training r2: 0.3409225675785782\n",
      "Validation Loss: 0.2657997725029562\n",
      "Validation correlation: 0.579899633202206\n",
      "Validation r2: 0.3334964865376083\n",
      "EPOCH: 99\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23558335803360483\n",
      "Training correlation: 0.584455562188362\n",
      "Training r2: 0.3415605427212779\n",
      "Validation Loss: 0.2663368204144177\n",
      "Validation correlation: 0.5798489151732859\n",
      "Validation r2: 0.332149797172102\n",
      "EPOCH: 100\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23522126934387932\n",
      "Training correlation: 0.5853262495649385\n",
      "Training r2: 0.3425725618885719\n",
      "Validation Loss: 0.26500045967276664\n",
      "Validation correlation: 0.5799192585396016\n",
      "Validation r2: 0.3355007819278115\n",
      "EPOCH: 101\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354249313396399\n",
      "Training correlation: 0.584822902969905\n",
      "Training r2: 0.34200334122683174\n",
      "Validation Loss: 0.2660447680299006\n",
      "Validation correlation: 0.579871998043465\n",
      "Validation r2: 0.33288213857669\n",
      "EPOCH: 102\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23539665042899316\n",
      "Training correlation: 0.5848821219985172\n",
      "Training r2: 0.34208238120516465\n",
      "Validation Loss: 0.26603846708593987\n",
      "Validation correlation: 0.5798731370782536\n",
      "Validation r2: 0.3328979599693238\n",
      "EPOCH: 103\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542968731374686\n",
      "Training correlation: 0.5848093918728039\n",
      "Training r2: 0.34199004755219364\n",
      "Validation Loss: 0.2648661767414222\n",
      "Validation correlation: 0.5800096066960947\n",
      "Validation r2: 0.3358375104238831\n",
      "EPOCH: 104\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23555884711946842\n",
      "Training correlation: 0.5844909818143859\n",
      "Training r2: 0.34162905013509204\n",
      "Validation Loss: 0.2649511323893329\n",
      "Validation correlation: 0.5799502971116375\n",
      "Validation r2: 0.33562447683417473\n",
      "EPOCH: 105\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23527707846964283\n",
      "Training correlation: 0.5851712589098781\n",
      "Training r2: 0.3424165732368274\n",
      "Validation Loss: 0.26480893556177526\n",
      "Validation correlation: 0.5800201991987268\n",
      "Validation r2: 0.33598103884934694\n",
      "EPOCH: 106\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23550465909453255\n",
      "Training correlation: 0.5846358900656148\n",
      "Training r2: 0.34178050527466985\n",
      "Validation Loss: 0.2659738353814226\n",
      "Validation correlation: 0.5798949750363936\n",
      "Validation r2: 0.33305999898249694\n",
      "EPOCH: 107\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23517535351964808\n",
      "Training correlation: 0.5854773027859419\n",
      "Training r2: 0.34270089340466003\n",
      "Validation Loss: 0.26516433077903284\n",
      "Validation correlation: 0.5800683893127543\n",
      "Validation r2: 0.3350898863446655\n",
      "EPOCH: 108\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23620696569820493\n",
      "Training correlation: 0.5831702508080427\n",
      "Training r2: 0.3398176096020973\n",
      "Validation Loss: 0.26705495667304796\n",
      "Validation correlation: 0.5798122582181868\n",
      "Validation r2: 0.33034905150851057\n",
      "EPOCH: 109\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23562488643214366\n",
      "Training correlation: 0.5843638225746632\n",
      "Training r2: 0.34144447197119576\n",
      "Validation Loss: 0.26573920297957354\n",
      "Validation correlation: 0.5799689340449099\n",
      "Validation r2: 0.333648364074166\n",
      "EPOCH: 110\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23532641832516402\n",
      "Training correlation: 0.5850763157114609\n",
      "Training r2: 0.34227867458854777\n",
      "Validation Loss: 0.2653229085708632\n",
      "Validation correlation: 0.5800328525255213\n",
      "Validation r2: 0.3346922252714707\n",
      "EPOCH: 111\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535992154123436\n",
      "Training correlation: 0.5850091607218808\n",
      "Training r2: 0.34218503620426155\n",
      "Validation Loss: 0.2661943665575174\n",
      "Validation correlation: 0.5799217402121015\n",
      "Validation r2: 0.33250701950631145\n",
      "EPOCH: 112\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23563628931543176\n",
      "Training correlation: 0.5843147853200357\n",
      "Training r2: 0.3414126078981803\n",
      "Validation Loss: 0.2660850210600158\n",
      "Validation correlation: 0.5799496414866372\n",
      "Validation r2: 0.3327811950720554\n",
      "EPOCH: 113\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2357844397248311\n",
      "Training correlation: 0.5839532488312056\n",
      "Training r2: 0.3409985305720893\n",
      "Validation Loss: 0.2651903987694776\n",
      "Validation correlation: 0.5800512615686251\n",
      "Validation r2: 0.33502450183524246\n",
      "EPOCH: 114\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535494811657837\n",
      "Training correlation: 0.584983147697657\n",
      "Training r2: 0.3421989346902643\n",
      "Validation Loss: 0.26514138066626775\n",
      "Validation correlation: 0.5800728495084879\n",
      "Validation r2: 0.33514742111743057\n",
      "EPOCH: 115\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23540495731934638\n",
      "Training correlation: 0.5848618802847717\n",
      "Training r2: 0.34205915751458305\n",
      "Validation Loss: 0.2650441732863518\n",
      "Validation correlation: 0.5800771190685856\n",
      "Validation r2: 0.33539116445167894\n",
      "EPOCH: 116\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2354288121567727\n",
      "Training correlation: 0.5848609083638525\n",
      "Training r2: 0.34199249212196403\n",
      "Validation Loss: 0.2666123223442983\n",
      "Validation correlation: 0.5799024097899581\n",
      "Validation r2: 0.33145897209077135\n",
      "EPOCH: 117\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535224348806846\n",
      "Training correlation: 0.5850310971300821\n",
      "Training r2: 0.342206498027364\n",
      "Validation Loss: 0.26563414502951443\n",
      "Validation correlation: 0.5800172543429212\n",
      "Validation r2: 0.3339118097313134\n",
      "EPOCH: 118\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23547392779092147\n",
      "Training correlation: 0.5847006154416008\n",
      "Training r2: 0.3418663938096169\n",
      "Validation Loss: 0.2673414922393529\n",
      "Validation correlation: 0.5799616618577884\n",
      "Validation r2: 0.32963055845455635\n",
      "EPOCH: 119\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23538920821887457\n",
      "Training correlation: 0.5849253775748625\n",
      "Training r2: 0.34210317739131413\n",
      "Validation Loss: 0.2650840798856137\n",
      "Validation correlation: 0.5801060278875687\n",
      "Validation r2: 0.3352910975792813\n",
      "EPOCH: 120\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535248934222242\n",
      "Training correlation: 0.5850058438621877\n",
      "Training r2: 0.3422058090756417\n",
      "Validation Loss: 0.2647310593959796\n",
      "Validation correlation: 0.5801448200791962\n",
      "Validation r2: 0.33617631789857405\n",
      "EPOCH: 121\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23526919879744537\n",
      "Training correlation: 0.5852120131475472\n",
      "Training r2: 0.3424386018941179\n",
      "Validation Loss: 0.26499032377651055\n",
      "Validation correlation: 0.5800770296102103\n",
      "Validation r2: 0.33552619540115747\n",
      "EPOCH: 122\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23584577125640116\n",
      "Training correlation: 0.583930633528099\n",
      "Training r2: 0.3408271190865254\n",
      "Validation Loss: 0.26573016411435285\n",
      "Validation correlation: 0.5800666854610516\n",
      "Validation r2: 0.33367104284904037\n",
      "EPOCH: 123\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23527056100639876\n",
      "Training correlation: 0.5851912929493883\n",
      "Training r2: 0.3424347914781485\n",
      "Validation Loss: 0.2658381574140077\n",
      "Validation correlation: 0.5800815721758211\n",
      "Validation r2: 0.3334002214064151\n",
      "EPOCH: 124\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23528900425864097\n",
      "Training correlation: 0.5851853025763363\n",
      "Training r2: 0.3423832452810759\n",
      "Validation Loss: 0.26687124401903894\n",
      "Validation correlation: 0.5800136821352153\n",
      "Validation r2: 0.33080972796268404\n",
      "EPOCH: 125\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542260853008123\n",
      "Training correlation: 0.5848268842781803\n",
      "Training r2: 0.3420098235913914\n",
      "Validation Loss: 0.2662146458001554\n",
      "Validation correlation: 0.5800833021341016\n",
      "Validation r2: 0.332456173784042\n",
      "EPOCH: 126\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23527004205856814\n",
      "Training correlation: 0.5851826039636974\n",
      "Training r2: 0.34243624125109184\n",
      "Validation Loss: 0.2662579775947894\n",
      "Validation correlation: 0.5800946804979554\n",
      "Validation r2: 0.3323475263521348\n",
      "EPOCH: 127\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23518293216019678\n",
      "Training correlation: 0.5853968991168405\n",
      "Training r2: 0.34267971490739857\n",
      "Validation Loss: 0.2679838532676848\n",
      "Validation correlation: 0.5799786691050657\n",
      "Validation r2: 0.32801980008773957\n",
      "EPOCH: 128\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23531099935839517\n",
      "Training correlation: 0.585100689322142\n",
      "Training r2: 0.3423217710314721\n",
      "Validation Loss: 0.265658339313301\n",
      "Validation correlation: 0.580080460741862\n",
      "Validation r2: 0.3338511205786723\n",
      "EPOCH: 129\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23536354719155586\n",
      "Training correlation: 0.5849676475608102\n",
      "Training r2: 0.34217490576504106\n",
      "Validation Loss: 0.26519925696914576\n",
      "Validation correlation: 0.5801703445222863\n",
      "Validation r2: 0.335002286042665\n",
      "EPOCH: 130\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23541197813172002\n",
      "Training correlation: 0.5848467429547086\n",
      "Training r2: 0.34203953864918535\n",
      "Validation Loss: 0.2650117689638484\n",
      "Validation correlation: 0.5800989458307766\n",
      "Validation r2: 0.33547243095107604\n",
      "EPOCH: 131\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352610928276744\n",
      "Training correlation: 0.5852678244639544\n",
      "Training r2: 0.3424612545976824\n",
      "Validation Loss: 0.26607002395662477\n",
      "Validation correlation: 0.5801184842078899\n",
      "Validation r2: 0.3328188090234415\n",
      "EPOCH: 132\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23546612448251425\n",
      "Training correlation: 0.5847149294246452\n",
      "Training r2: 0.34188820901589023\n",
      "Validation Loss: 0.2651735652100578\n",
      "Validation correlation: 0.5801986076867476\n",
      "Validation r2: 0.33506672211565214\n",
      "EPOCH: 133\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2353089382345079\n",
      "Training correlation: 0.5850918106353982\n",
      "Training r2: 0.34232753057169596\n",
      "Validation Loss: 0.26556631349593285\n",
      "Validation correlation: 0.5801821343969045\n",
      "Validation r2: 0.3340818842669693\n",
      "EPOCH: 134\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23541818757882232\n",
      "Training correlation: 0.5848307346166938\n",
      "Training r2: 0.34202218066132417\n",
      "Validation Loss: 0.2654368899091919\n",
      "Validation correlation: 0.5801884382128316\n",
      "Validation r2: 0.33440642902634365\n",
      "EPOCH: 135\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23525905591669627\n",
      "Training correlation: 0.5852204396875937\n",
      "Training r2: 0.3424669525205174\n",
      "Validation Loss: 0.2663977903820663\n",
      "Validation correlation: 0.5801154290435745\n",
      "Validation r2: 0.3319969285396427\n",
      "EPOCH: 136\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23529475924806476\n",
      "Training correlation: 0.585183555876215\n",
      "Training r2: 0.34236716087930485\n",
      "Validation Loss: 0.2647295824085244\n",
      "Validation correlation: 0.5803061669492746\n",
      "Validation r2: 0.33618003361169224\n",
      "EPOCH: 137\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2353941467210655\n",
      "Training correlation: 0.5848845837873031\n",
      "Training r2: 0.34208938418252954\n",
      "Validation Loss: 0.26563075335970876\n",
      "Validation correlation: 0.5802129158009848\n",
      "Validation r2: 0.33392030876516143\n",
      "EPOCH: 138\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23532083585271757\n",
      "Training correlation: 0.5850614382699318\n",
      "Training r2: 0.34229427713142724\n",
      "Validation Loss: 0.26535806757740976\n",
      "Validation correlation: 0.580229758374864\n",
      "Validation r2: 0.33460407271734294\n",
      "EPOCH: 139\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23554824559034498\n",
      "Training correlation: 0.5845159695398705\n",
      "Training r2: 0.3416586810910305\n",
      "Validation Loss: 0.2665108423171918\n",
      "Validation correlation: 0.5801773782860697\n",
      "Validation r2: 0.3317134353796126\n",
      "EPOCH: 140\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23530003556690093\n",
      "Training correlation: 0.585167411781544\n",
      "Training r2: 0.3423524141745511\n",
      "Validation Loss: 0.265645163765687\n",
      "Validation correlation: 0.5802338088219517\n",
      "Validation r2: 0.33388416622229333\n",
      "EPOCH: 141\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23520590811558603\n",
      "Training correlation: 0.5853559240383869\n",
      "Training r2: 0.34261549130873425\n",
      "Validation Loss: 0.26474976107446313\n",
      "Validation correlation: 0.5803263126154368\n",
      "Validation r2: 0.33612941922512485\n",
      "EPOCH: 142\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23527174068726814\n",
      "Training correlation: 0.5851879020106909\n",
      "Training r2: 0.34243149629020053\n",
      "Validation Loss: 0.2653391554328702\n",
      "Validation correlation: 0.5802279663964962\n",
      "Validation r2: 0.33465148743808326\n",
      "EPOCH: 143\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23530333969772754\n",
      "Training correlation: 0.5851269259835956\n",
      "Training r2: 0.34234317856765994\n",
      "Validation Loss: 0.2657287076147439\n",
      "Validation correlation: 0.5802175839875522\n",
      "Validation r2: 0.33367468334323447\n",
      "EPOCH: 144\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23520053727327778\n",
      "Training correlation: 0.5853588923501176\n",
      "Training r2: 0.34263050186315036\n",
      "Validation Loss: 0.26759426011011883\n",
      "Validation correlation: 0.5801716378195576\n",
      "Validation r2: 0.3289967234317488\n",
      "EPOCH: 145\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535490783933535\n",
      "Training correlation: 0.5849877675147162\n",
      "Training r2: 0.34219904965444936\n",
      "Validation Loss: 0.2668578915309353\n",
      "Validation correlation: 0.5802229374041773\n",
      "Validation r2: 0.33084319675355234\n",
      "EPOCH: 146\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23499830802984997\n",
      "Training correlation: 0.5859288068965605\n",
      "Training r2: 0.3431957224791343\n",
      "Validation Loss: 0.2646207211692049\n",
      "Validation correlation: 0.5803904236557498\n",
      "Validation r2: 0.3364529891632194\n",
      "EPOCH: 147\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23515827177790996\n",
      "Training correlation: 0.5854585070734589\n",
      "Training r2: 0.3427486336475388\n",
      "Validation Loss: 0.2665473721468998\n",
      "Validation correlation: 0.5802378730747078\n",
      "Validation r2: 0.33162182832679354\n",
      "EPOCH: 148\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23530482227277713\n",
      "Training correlation: 0.5851014988766259\n",
      "Training r2: 0.34233903326383097\n",
      "Validation Loss: 0.26552547004334187\n",
      "Validation correlation: 0.580241044868552\n",
      "Validation r2: 0.33418431362572754\n",
      "EPOCH: 149\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23518234569560037\n",
      "Training correlation: 0.5854033640397676\n",
      "Training r2: 0.3426813457565515\n",
      "Validation Loss: 0.2648332620852962\n",
      "Validation correlation: 0.5803002553326291\n",
      "Validation r2: 0.3359200441672854\n",
      "EPOCH: 150\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351502093448121\n",
      "Training correlation: 0.5854728529155371\n",
      "Training r2: 0.34277116533769425\n",
      "Validation Loss: 0.26562500186253146\n",
      "Validation correlation: 0.5803144250710264\n",
      "Validation r2: 0.33393472146253544\n",
      "EPOCH: 151\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23522927892764675\n",
      "Training correlation: 0.5852796626422552\n",
      "Training r2: 0.342550173753871\n",
      "Validation Loss: 0.26561805648268233\n",
      "Validation correlation: 0.5803239181645687\n",
      "Validation r2: 0.33395213155598535\n",
      "EPOCH: 152\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542338171345742\n",
      "Training correlation: 0.5848152993687878\n",
      "Training r2: 0.3420076682701515\n",
      "Validation Loss: 0.2654313749535112\n",
      "Validation correlation: 0.5802824987087264\n",
      "Validation r2: 0.3344202730025676\n",
      "EPOCH: 153\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23512865589783255\n",
      "Training correlation: 0.5855266489141566\n",
      "Training r2: 0.3428314063070842\n",
      "Validation Loss: 0.265054305457545\n",
      "Validation correlation: 0.5803730371873723\n",
      "Validation r2: 0.3353657734516694\n",
      "EPOCH: 154\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23534366909163298\n",
      "Training correlation: 0.5850144278514242\n",
      "Training r2: 0.34223046318826245\n",
      "Validation Loss: 0.2654790091958394\n",
      "Validation correlation: 0.5803470876439802\n",
      "Validation r2: 0.3343008006611865\n",
      "EPOCH: 155\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351933821258219\n",
      "Training correlation: 0.5853741902010878\n",
      "Training r2: 0.34265050621057425\n",
      "Validation Loss: 0.2652577311446254\n",
      "Validation correlation: 0.5803596367198676\n",
      "Validation r2: 0.3348556734755894\n",
      "EPOCH: 156\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23529190328887298\n",
      "Training correlation: 0.5851292748228544\n",
      "Training r2: 0.3423751423552709\n",
      "Validation Loss: 0.2648552641695434\n",
      "Validation correlation: 0.5804322217961233\n",
      "Validation r2: 0.3358648638850845\n",
      "EPOCH: 157\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23531217717673308\n",
      "Training correlation: 0.5851297686249626\n",
      "Training r2: 0.34231848107438767\n",
      "Validation Loss: 0.26519917129269815\n",
      "Validation correlation: 0.5804256117676532\n",
      "Validation r2: 0.335002513424673\n",
      "EPOCH: 158\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23540019668891077\n",
      "Training correlation: 0.5848811342694512\n",
      "Training r2: 0.3420724650678114\n",
      "Validation Loss: 0.26480568730689275\n",
      "Validation correlation: 0.5804448355703196\n",
      "Validation r2: 0.33598917757237956\n",
      "EPOCH: 159\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23528066966313213\n",
      "Training correlation: 0.5851619548738014\n",
      "Training r2: 0.34240654352879085\n",
      "Validation Loss: 0.26480161022550636\n",
      "Validation correlation: 0.5804850422495003\n",
      "Validation r2: 0.33599942277460215\n",
      "EPOCH: 160\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23543912336380335\n",
      "Training correlation: 0.5847812630610802\n",
      "Training r2: 0.34196367436570596\n",
      "Validation Loss: 0.2652936295761653\n",
      "Validation correlation: 0.5804172586460357\n",
      "Validation r2: 0.3347656386967862\n",
      "EPOCH: 161\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23544630784612988\n",
      "Training correlation: 0.5847602380010105\n",
      "Training r2: 0.3419435932062954\n",
      "Validation Loss: 0.2659766273160951\n",
      "Validation correlation: 0.5803644158422903\n",
      "Validation r2: 0.33305301965223066\n",
      "EPOCH: 162\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23532929034868974\n",
      "Training correlation: 0.5850896083979739\n",
      "Training r2: 0.3422706480721187\n",
      "Validation Loss: 0.2648228356341309\n",
      "Validation correlation: 0.5804757654349872\n",
      "Validation r2: 0.3359461937016569\n",
      "EPOCH: 163\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23530063180978755\n",
      "Training correlation: 0.5851867613781947\n",
      "Training r2: 0.34235074855930214\n",
      "Validation Loss: 0.2653121617642852\n",
      "Validation correlation: 0.5804312474910759\n",
      "Validation r2: 0.3347191929263649\n",
      "EPOCH: 164\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23516521040608251\n",
      "Training correlation: 0.585439460803005\n",
      "Training r2: 0.34272924090606427\n",
      "Validation Loss: 0.2651613823917169\n",
      "Validation correlation: 0.5804388735116374\n",
      "Validation r2: 0.33509727225121055\n",
      "EPOCH: 165\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352351018994692\n",
      "Training correlation: 0.5852953891697573\n",
      "Training r2: 0.34253389999656925\n",
      "Validation Loss: 0.2650259689037706\n",
      "Validation correlation: 0.5804770754238078\n",
      "Validation r2: 0.33543681371398315\n",
      "EPOCH: 166\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23519094896127365\n",
      "Training correlation: 0.5853757007083076\n",
      "Training r2: 0.3426572978224285\n",
      "Validation Loss: 0.26488759585331956\n",
      "Validation correlation: 0.580458030091086\n",
      "Validation r2: 0.33578379039615813\n",
      "EPOCH: 167\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23536703105666923\n",
      "Training correlation: 0.5849503290339286\n",
      "Training r2: 0.3421651641537444\n",
      "Validation Loss: 0.2649421587127136\n",
      "Validation correlation: 0.5804732917016908\n",
      "Validation r2: 0.3356469897369797\n",
      "EPOCH: 168\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351916394948159\n",
      "Training correlation: 0.5853688023502213\n",
      "Training r2: 0.34265537228848575\n",
      "Validation Loss: 0.26674122442222786\n",
      "Validation correlation: 0.580356413538621\n",
      "Validation r2: 0.3311357372278232\n",
      "EPOCH: 169\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23513729711258452\n",
      "Training correlation: 0.5855168115918545\n",
      "Training r2: 0.3428072562627099\n",
      "Validation Loss: 0.2649170815890105\n",
      "Validation correlation: 0.5805089925686638\n",
      "Validation r2: 0.335709850313998\n",
      "EPOCH: 170\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535450110902573\n",
      "Training correlation: 0.584995135384432\n",
      "Training r2: 0.34220018546871667\n",
      "Validation Loss: 0.2651489499941591\n",
      "Validation correlation: 0.5804767913171425\n",
      "Validation r2: 0.33512843528526237\n",
      "EPOCH: 171\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351529859136\n",
      "Training correlation: 0.5854905800828614\n",
      "Training r2: 0.34276340828032914\n",
      "Validation Loss: 0.2660916945102704\n",
      "Validation correlation: 0.5804477779185927\n",
      "Validation r2: 0.3327644624842768\n",
      "EPOCH: 172\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23514081520171365\n",
      "Training correlation: 0.5855017814762276\n",
      "Training r2: 0.34279742503564936\n",
      "Validation Loss: 0.2652804652037401\n",
      "Validation correlation: 0.5805374251971991\n",
      "Validation r2: 0.3347986611674796\n",
      "EPOCH: 173\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23522781055439962\n",
      "Training correlation: 0.5852833853104079\n",
      "Training r2: 0.342554282724011\n",
      "Validation Loss: 0.26496605871652806\n",
      "Validation correlation: 0.5805538406740399\n",
      "Validation r2: 0.3355870361088351\n",
      "EPOCH: 174\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23508888293520358\n",
      "Training correlation: 0.5856250622207604\n",
      "Training r2: 0.34294257351374235\n",
      "Validation Loss: 0.26525082487793716\n",
      "Validation correlation: 0.5804983361204809\n",
      "Validation r2: 0.3348729884004322\n",
      "EPOCH: 175\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23516250228532612\n",
      "Training correlation: 0.5854984652100093\n",
      "Training r2: 0.3427368132438574\n",
      "Validation Loss: 0.26513132299633335\n",
      "Validation correlation: 0.5805490611834324\n",
      "Validation r2: 0.33517263844589673\n",
      "EPOCH: 176\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23524487250674087\n",
      "Training correlation: 0.5852695381470993\n",
      "Training r2: 0.342506584977867\n",
      "Validation Loss: 0.2648074138735648\n",
      "Validation correlation: 0.580576404801125\n",
      "Validation r2: 0.3359848635066094\n",
      "EPOCH: 177\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23492764917349793\n",
      "Training correlation: 0.5860376295184346\n",
      "Training r2: 0.34339320680812924\n",
      "Validation Loss: 0.2665199370583565\n",
      "Validation correlation: 0.5804929087323072\n",
      "Validation r2: 0.33169064070683185\n",
      "EPOCH: 178\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23541110483727734\n",
      "Training correlation: 0.5848741104290909\n",
      "Training r2: 0.3420419826659521\n",
      "Validation Loss: 0.2655647936702539\n",
      "Validation correlation: 0.5804861450331014\n",
      "Validation r2: 0.33408569115301257\n",
      "EPOCH: 179\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352008133935681\n",
      "Training correlation: 0.5853844655462425\n",
      "Training r2: 0.3426297362906885\n",
      "Validation Loss: 0.26552687439206973\n",
      "Validation correlation: 0.5804460946497797\n",
      "Validation r2: 0.3341807775542679\n",
      "EPOCH: 180\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2353499518759119\n",
      "Training correlation: 0.5849982412298341\n",
      "Training r2: 0.3422129000433718\n",
      "Validation Loss: 0.26606401915516764\n",
      "Validation correlation: 0.5805303806925728\n",
      "Validation r2: 0.3328338563814618\n",
      "EPOCH: 181\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23517238790391604\n",
      "Training correlation: 0.5854481729286003\n",
      "Training r2: 0.34270918072105805\n",
      "Validation Loss: 0.26526108742633314\n",
      "Validation correlation: 0.5805739008657498\n",
      "Validation r2: 0.33484725137303384\n",
      "EPOCH: 182\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350382113696818\n",
      "Training correlation: 0.5857464038902229\n",
      "Training r2: 0.34308419461470085\n",
      "Validation Loss: 0.2662577485034187\n",
      "Validation correlation: 0.5805383320334869\n",
      "Validation r2: 0.33234809687804556\n",
      "EPOCH: 183\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23524041546893476\n",
      "Training correlation: 0.5852580479775957\n",
      "Training r2: 0.3425190549205629\n",
      "Validation Loss: 0.2650947466033386\n",
      "Validation correlation: 0.5805930428169253\n",
      "Validation r2: 0.33526435994684\n",
      "EPOCH: 184\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23496461041205752\n",
      "Training correlation: 0.5859240592048647\n",
      "Training r2: 0.34328991140377674\n",
      "Validation Loss: 0.2644879226754415\n",
      "Validation correlation: 0.5806444018409687\n",
      "Validation r2: 0.33678600172226225\n",
      "EPOCH: 185\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23530071934876662\n",
      "Training correlation: 0.5851327529164339\n",
      "Training r2: 0.34235050171620307\n",
      "Validation Loss: 0.26536211485829264\n",
      "Validation correlation: 0.5805643520277646\n",
      "Validation r2: 0.33459392255933906\n",
      "EPOCH: 186\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23527949603549\n",
      "Training correlation: 0.5851924979185299\n",
      "Training r2: 0.3424098209526405\n",
      "Validation Loss: 0.26457594032508774\n",
      "Validation correlation: 0.5806871060622063\n",
      "Validation r2: 0.3365652910361999\n",
      "EPOCH: 187\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23487780852982793\n",
      "Training correlation: 0.586283880388544\n",
      "Training r2: 0.3435325094033109\n",
      "Validation Loss: 0.2683494272194223\n",
      "Validation correlation: 0.5804435464736976\n",
      "Validation r2: 0.32710310950388555\n",
      "EPOCH: 188\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23544544828785677\n",
      "Training correlation: 0.584796470363997\n",
      "Training r2: 0.34194599535833237\n",
      "Validation Loss: 0.2648885010436136\n",
      "Validation correlation: 0.5806334433471535\n",
      "Validation r2: 0.33578153178960535\n",
      "EPOCH: 189\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350730958856531\n",
      "Training correlation: 0.5856585501326198\n",
      "Training r2: 0.3429866888188372\n",
      "Validation Loss: 0.26503810143376183\n",
      "Validation correlation: 0.5806412132607799\n",
      "Validation r2: 0.33540639691290397\n",
      "EPOCH: 190\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351254407028836\n",
      "Training correlation: 0.585528646283558\n",
      "Training r2: 0.34284039215651485\n",
      "Validation Loss: 0.2655170253256599\n",
      "Validation correlation: 0.5806367236255192\n",
      "Validation r2: 0.33420547453666516\n",
      "EPOCH: 191\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23504219858392478\n",
      "Training correlation: 0.5857517089711699\n",
      "Training r2: 0.3430730554950794\n",
      "Validation Loss: 0.26463014557843967\n",
      "Validation correlation: 0.5807113207006993\n",
      "Validation r2: 0.3364293698710341\n",
      "EPOCH: 192\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23546958599725\n",
      "Training correlation: 0.584708323423232\n",
      "Training r2: 0.34187853666682044\n",
      "Validation Loss: 0.2647669671401768\n",
      "Validation correlation: 0.5806246937973565\n",
      "Validation r2: 0.336086294436983\n",
      "EPOCH: 193\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23504985801177597\n",
      "Training correlation: 0.5857106361947412\n",
      "Training r2: 0.34305164350060624\n",
      "Validation Loss: 0.26458637795144185\n",
      "Validation correlation: 0.5806722418476721\n",
      "Validation r2: 0.3365391021168188\n",
      "EPOCH: 194\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23520878223445962\n",
      "Training correlation: 0.5853309252536057\n",
      "Training r2: 0.34260745454264774\n",
      "Validation Loss: 0.26494384616622485\n",
      "Validation correlation: 0.5806821069564845\n",
      "Validation r2: 0.33564275590180015\n",
      "EPOCH: 195\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23509143809556307\n",
      "Training correlation: 0.5856185984651112\n",
      "Training r2: 0.34293543051676045\n",
      "Validation Loss: 0.26521307881517964\n",
      "Validation correlation: 0.5806629050639336\n",
      "Validation r2: 0.3349676348884133\n",
      "EPOCH: 196\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23509362680285595\n",
      "Training correlation: 0.5856049675111723\n",
      "Training r2: 0.34292930843189984\n",
      "Validation Loss: 0.2667007423007419\n",
      "Validation correlation: 0.5805267396679765\n",
      "Validation r2: 0.33123727459646335\n",
      "EPOCH: 197\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23501908037769456\n",
      "Training correlation: 0.5858138313032145\n",
      "Training r2: 0.3431376629307916\n",
      "Validation Loss: 0.26444739399066886\n",
      "Validation correlation: 0.5807625176503458\n",
      "Validation r2: 0.3368876164326632\n",
      "EPOCH: 198\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352518709687369\n",
      "Training correlation: 0.5852527567684258\n",
      "Training r2: 0.3424870338970809\n",
      "Validation Loss: 0.264648834219203\n",
      "Validation correlation: 0.5807082167397638\n",
      "Validation r2: 0.3363824974376137\n",
      "EPOCH: 199\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351622047459239\n",
      "Training correlation: 0.5854438522284799\n",
      "Training r2: 0.3427376382053642\n",
      "Validation Loss: 0.26885509706321997\n",
      "Validation correlation: 0.5804437846597157\n",
      "Validation r2: 0.3258351333885934\n",
      "EPOCH: 200\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535060702135624\n",
      "Training correlation: 0.5850230635941547\n",
      "Training r2: 0.3422110719885296\n",
      "Validation Loss: 0.2654219654445282\n",
      "Validation correlation: 0.5807090347477672\n",
      "Validation r2: 0.334443840857241\n",
      "EPOCH: 201\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350712675781995\n",
      "Training correlation: 0.5856659756642196\n",
      "Training r2: 0.3429918019547553\n",
      "Validation Loss: 0.26544117559410285\n",
      "Validation correlation: 0.5807289618098956\n",
      "Validation r2: 0.3343956672829239\n",
      "EPOCH: 202\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23512256914499077\n",
      "Training correlation: 0.5855387224796177\n",
      "Training r2: 0.34284841756825324\n",
      "Validation Loss: 0.2648814643997225\n",
      "Validation correlation: 0.5807479813066851\n",
      "Validation r2: 0.3357991793709172\n",
      "EPOCH: 203\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23504309562564368\n",
      "Training correlation: 0.5857270540560848\n",
      "Training r2: 0.34307053783696395\n",
      "Validation Loss: 0.26476408021639936\n",
      "Validation correlation: 0.5807399500896171\n",
      "Validation r2: 0.3360935091560401\n",
      "EPOCH: 204\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23502590213201743\n",
      "Training correlation: 0.5857734755154476\n",
      "Training r2: 0.34311860089792046\n",
      "Validation Loss: 0.2657164558827386\n",
      "Validation correlation: 0.5807360557485519\n",
      "Validation r2: 0.3337053874891681\n",
      "EPOCH: 205\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23497462501095168\n",
      "Training correlation: 0.5858923878986846\n",
      "Training r2: 0.34326191746054535\n",
      "Validation Loss: 0.26558280062449935\n",
      "Validation correlation: 0.5806993829928273\n",
      "Validation r2: 0.334040540185935\n",
      "EPOCH: 206\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23508797425266298\n",
      "Training correlation: 0.5856274617332156\n",
      "Training r2: 0.3429451080230129\n",
      "Validation Loss: 0.2654715609324935\n",
      "Validation correlation: 0.5807467560725905\n",
      "Validation r2: 0.3343194738340065\n",
      "EPOCH: 207\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23508653707681795\n",
      "Training correlation: 0.5856252192394433\n",
      "Training r2: 0.3429491242952547\n",
      "Validation Loss: 0.26475141313987643\n",
      "Validation correlation: 0.5808091500487169\n",
      "Validation r2: 0.33612527972930517\n",
      "EPOCH: 208\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23513485626509395\n",
      "Training correlation: 0.5855223316946149\n",
      "Training r2: 0.3428140787609283\n",
      "Validation Loss: 0.26596047171813014\n",
      "Validation correlation: 0.5807248707945338\n",
      "Validation r2: 0.3330935049029671\n",
      "EPOCH: 209\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350655742851306\n",
      "Training correlation: 0.5857197591048195\n",
      "Training r2: 0.3430077201655072\n",
      "Validation Loss: 0.2648482536010928\n",
      "Validation correlation: 0.580769238405991\n",
      "Validation r2: 0.3358824439059448\n",
      "EPOCH: 210\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23523506558010554\n",
      "Training correlation: 0.5853043698661979\n",
      "Training r2: 0.34253399891672487\n",
      "Validation Loss: 0.26536948303278535\n",
      "Validation correlation: 0.5807819552814651\n",
      "Validation r2: 0.3345754343983248\n",
      "EPOCH: 211\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23469472983496778\n",
      "Training correlation: 0.5865651922210328\n",
      "Training r2: 0.34404419913651785\n",
      "Validation Loss: 0.2643744274578263\n",
      "Validation correlation: 0.580841102020935\n",
      "Validation r2: 0.33707058031452775\n",
      "EPOCH: 212\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23510901759883635\n",
      "Training correlation: 0.5855659341810412\n",
      "Training r2: 0.34288629533915527\n",
      "Validation Loss: 0.26448833429489627\n",
      "Validation correlation: 0.5808560674317846\n",
      "Validation r2: 0.33678496763491794\n",
      "EPOCH: 213\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23533761190647828\n",
      "Training correlation: 0.5850318514827317\n",
      "Training r2: 0.34224739197298115\n",
      "Validation Loss: 0.2648133013355394\n",
      "Validation correlation: 0.5808265215889332\n",
      "Validation r2: 0.335970105779266\n",
      "EPOCH: 214\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23509076525606976\n",
      "Training correlation: 0.5856171428621584\n",
      "Training r2: 0.34293730927190025\n",
      "Validation Loss: 0.264922611444943\n",
      "Validation correlation: 0.5808389996824326\n",
      "Validation r2: 0.33569599855771837\n",
      "EPOCH: 215\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23528291704016632\n",
      "Training correlation: 0.5851518709187504\n",
      "Training r2: 0.34240025095840654\n",
      "Validation Loss: 0.26466628427653915\n",
      "Validation correlation: 0.5808337786807626\n",
      "Validation r2: 0.33633875528209856\n",
      "EPOCH: 216\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350994525684756\n",
      "Training correlation: 0.5855930576347786\n",
      "Training r2: 0.3429130301512078\n",
      "Validation Loss: 0.264776611328125\n",
      "Validation correlation: 0.5808664959486047\n",
      "Validation r2: 0.33606208249833147\n",
      "EPOCH: 217\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23555524568205605\n",
      "Training correlation: 0.5845173022912398\n",
      "Training r2: 0.34163911919370304\n",
      "Validation Loss: 0.26441880972020904\n",
      "Validation correlation: 0.5809239754507791\n",
      "Validation r2: 0.33695930519384054\n",
      "EPOCH: 218\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352950728518009\n",
      "Training correlation: 0.5851348551870815\n",
      "Training r2: 0.34236628141013736\n",
      "Validation Loss: 0.26504586632745747\n",
      "Validation correlation: 0.580837400960297\n",
      "Validation r2: 0.33538690852523967\n",
      "EPOCH: 219\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350864323094228\n",
      "Training correlation: 0.5856218171860617\n",
      "Training r2: 0.34294941876202556\n",
      "Validation Loss: 0.26545024798489\n",
      "Validation correlation: 0.580792056360507\n",
      "Validation r2: 0.3343729436085906\n",
      "EPOCH: 220\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23505327971490156\n",
      "Training correlation: 0.5857236235884206\n",
      "Training r2: 0.3430420747228651\n",
      "Validation Loss: 0.2657348297556836\n",
      "Validation correlation: 0.5807756662383069\n",
      "Validation r2: 0.33365932097557616\n",
      "EPOCH: 221\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23500898522431435\n",
      "Training correlation: 0.5858347077269948\n",
      "Training r2: 0.3431658837173016\n",
      "Validation Loss: 0.2649636951640935\n",
      "Validation correlation: 0.5808360282773191\n",
      "Validation r2: 0.3355929768755326\n",
      "EPOCH: 222\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542777379547855\n",
      "Training correlation: 0.5848201715940482\n",
      "Training r2: 0.3419953977283977\n",
      "Validation Loss: 0.26475323842071635\n",
      "Validation correlation: 0.5808162235965266\n",
      "Validation r2: 0.3361207044664949\n",
      "EPOCH: 223\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23510003740335697\n",
      "Training correlation: 0.5856017943394799\n",
      "Training r2: 0.34291140065982895\n",
      "Validation Loss: 0.265479975849672\n",
      "Validation correlation: 0.5808416932057543\n",
      "Validation r2: 0.3342983795109281\n",
      "EPOCH: 224\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23534847977760182\n",
      "Training correlation: 0.585066505689945\n",
      "Training r2: 0.3422170083497955\n",
      "Validation Loss: 0.26512201965164406\n",
      "Validation correlation: 0.5808329078983905\n",
      "Validation r2: 0.33519596784391426\n",
      "EPOCH: 225\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23499600151744163\n",
      "Training correlation: 0.5858437761598272\n",
      "Training r2: 0.3432021674752871\n",
      "Validation Loss: 0.266085224075946\n",
      "Validation correlation: 0.5807267063073273\n",
      "Validation r2: 0.33278069966724544\n",
      "EPOCH: 226\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23502478973509736\n",
      "Training correlation: 0.5857722829730049\n",
      "Training r2: 0.3431217097000464\n",
      "Validation Loss: 0.2668393220921861\n",
      "Validation correlation: 0.5807993869062624\n",
      "Validation r2: 0.3308897659000435\n",
      "EPOCH: 227\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351991191883803\n",
      "Training correlation: 0.5853618355875101\n",
      "Training r2: 0.3426344738026387\n",
      "Validation Loss: 0.2658350898246777\n",
      "Validation correlation: 0.5808954817202621\n",
      "Validation r2: 0.33340793435425453\n",
      "EPOCH: 228\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23483454774420617\n",
      "Training correlation: 0.5862260745275537\n",
      "Training r2: 0.34365341848161524\n",
      "Validation Loss: 0.26472476217708174\n",
      "Validation correlation: 0.5809470717094738\n",
      "Validation r2: 0.3361921005188727\n",
      "EPOCH: 229\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23501262461080544\n",
      "Training correlation: 0.5858218669596871\n",
      "Training r2: 0.3431557007562481\n",
      "Validation Loss: 0.26528270769162915\n",
      "Validation correlation: 0.5808919301494558\n",
      "Validation r2: 0.33479304827336365\n",
      "EPOCH: 230\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23529407406930047\n",
      "Training correlation: 0.585141721227545\n",
      "Training r2: 0.34236907825965535\n",
      "Validation Loss: 0.2651318426426133\n",
      "Validation correlation: 0.5809446987396293\n",
      "Validation r2: 0.3351713372877927\n",
      "EPOCH: 231\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23518932879171175\n",
      "Training correlation: 0.585399406519958\n",
      "Training r2: 0.3426618231324192\n",
      "Validation Loss: 0.2671799586100807\n",
      "Validation correlation: 0.5808542653829746\n",
      "Validation r2: 0.3300356098124788\n",
      "EPOCH: 232\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2349962964958631\n",
      "Training correlation: 0.5858356485429264\n",
      "Training r2: 0.34320133598322156\n",
      "Validation Loss: 0.2658556260966585\n",
      "Validation correlation: 0.5809530634793922\n",
      "Validation r2: 0.3333564243329481\n",
      "EPOCH: 233\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23507075538204544\n",
      "Training correlation: 0.5856571731981763\n",
      "Training r2: 0.34299323458283293\n",
      "Validation Loss: 0.2663731435031326\n",
      "Validation correlation: 0.5808757273185069\n",
      "Validation r2: 0.33205871231144213\n",
      "EPOCH: 234\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348202779593539\n",
      "Training correlation: 0.5862732337631245\n",
      "Training r2: 0.343693302748192\n",
      "Validation Loss: 0.26432854958267377\n",
      "Validation correlation: 0.5810509801687749\n",
      "Validation r2: 0.3371856046166162\n",
      "EPOCH: 235\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23514354427594908\n",
      "Training correlation: 0.5855326884863776\n",
      "Training r2: 0.3427897985482743\n",
      "Validation Loss: 0.2655075804285789\n",
      "Validation correlation: 0.5809352968135448\n",
      "Validation r2: 0.33422916211567955\n",
      "EPOCH: 236\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23519962626257282\n",
      "Training correlation: 0.585481292425382\n",
      "Training r2: 0.3426330552265041\n",
      "Validation Loss: 0.2646183073284206\n",
      "Validation correlation: 0.5810679961630975\n",
      "Validation r2: 0.3364590559160062\n",
      "EPOCH: 237\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23508169984977567\n",
      "Training correlation: 0.5856855403035827\n",
      "Training r2: 0.3429626409036939\n",
      "Validation Loss: 0.26548535670308687\n",
      "Validation correlation: 0.5809774319898866\n",
      "Validation r2: 0.33428489436906506\n",
      "EPOCH: 238\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23491688560413668\n",
      "Training correlation: 0.5860664486427387\n",
      "Training r2: 0.34342328711319936\n",
      "Validation Loss: 0.2643548168639857\n",
      "Validation correlation: 0.5810693222205495\n",
      "Validation r2: 0.3371197641331358\n",
      "EPOCH: 239\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23537410960751842\n",
      "Training correlation: 0.5849428358387116\n",
      "Training r2: 0.3421453788967589\n",
      "Validation Loss: 0.26442665470275784\n",
      "Validation correlation: 0.5810483342593012\n",
      "Validation r2: 0.3369396535234026\n",
      "EPOCH: 240\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23503834640321333\n",
      "Training correlation: 0.5857465394480733\n",
      "Training r2: 0.34308382398125725\n",
      "Validation Loss: 0.26568154459287746\n",
      "Validation correlation: 0.5809056363007317\n",
      "Validation r2: 0.3337929391493344\n",
      "EPOCH: 241\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348659651578473\n",
      "Training correlation: 0.5861492713825996\n",
      "Training r2: 0.3435656073285759\n",
      "Validation Loss: 0.26586832297368496\n",
      "Validation correlation: 0.5809742595794989\n",
      "Validation r2: 0.33332458492057127\n",
      "EPOCH: 242\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23500009815540843\n",
      "Training correlation: 0.5858278575762401\n",
      "Training r2: 0.34319071702954784\n",
      "Validation Loss: 0.2647005269176028\n",
      "Validation correlation: 0.5810187068786996\n",
      "Validation r2: 0.3362528747854344\n",
      "EPOCH: 243\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2349782529894375\n",
      "Training correlation: 0.5859028709992276\n",
      "Training r2: 0.34325177746412205\n",
      "Validation Loss: 0.26495514614464927\n",
      "Validation correlation: 0.5810423926633561\n",
      "Validation r2: 0.3356144298529192\n",
      "EPOCH: 244\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23563677264234806\n",
      "Training correlation: 0.5843106228586132\n",
      "Training r2: 0.3414112581461535\n",
      "Validation Loss: 0.2643777315886529\n",
      "Validation correlation: 0.5811085335278889\n",
      "Validation r2: 0.3370622980860657\n",
      "EPOCH: 245\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23511291494593592\n",
      "Training correlation: 0.5855779413554907\n",
      "Training r2: 0.34287540854708987\n",
      "Validation Loss: 0.26544838172835766\n",
      "Validation correlation: 0.5810130250670511\n",
      "Validation r2: 0.33437762236678337\n",
      "EPOCH: 246\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23485724385424217\n",
      "Training correlation: 0.586265111240424\n",
      "Training r2: 0.34358998910873817\n",
      "Validation Loss: 0.2683967057182398\n",
      "Validation correlation: 0.5808480479900855\n",
      "Validation r2: 0.32698456083636684\n",
      "EPOCH: 247\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23507064851930237\n",
      "Training correlation: 0.5857557371784965\n",
      "Training r2: 0.3429935360308908\n",
      "Validation Loss: 0.2651948762951299\n",
      "Validation correlation: 0.5810569084195015\n",
      "Validation r2: 0.33501327539083636\n",
      "EPOCH: 248\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23489944066876203\n",
      "Training correlation: 0.5860754215438515\n",
      "Training r2: 0.34347204938370046\n",
      "Validation Loss: 0.26461655096124503\n",
      "Validation correlation: 0.5810644967673941\n",
      "Validation r2: 0.336463465688427\n",
      "EPOCH: 249\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23480556372792974\n",
      "Training correlation: 0.586307983648022\n",
      "Training r2: 0.3437344251677792\n",
      "Validation Loss: 0.2646169234675389\n",
      "Validation correlation: 0.5811003015049763\n",
      "Validation r2: 0.3364625201264916\n",
      "EPOCH: 250\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23497329725883048\n",
      "Training correlation: 0.5859411162571866\n",
      "Training r2: 0.34326562522789217\n",
      "Validation Loss: 0.26515157057593647\n",
      "Validation correlation: 0.5810189721572026\n",
      "Validation r2: 0.3351218549965609\n",
      "EPOCH: 251\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23513338602931536\n",
      "Training correlation: 0.5855096515406724\n",
      "Training r2: 0.34281818366135863\n",
      "Validation Loss: 0.26541120560022985\n",
      "Validation correlation: 0.5810864286187118\n",
      "Validation r2: 0.3344708240481853\n",
      "EPOCH: 252\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23476960569538283\n",
      "Training correlation: 0.5863773875144017\n",
      "Training r2: 0.3438349303316204\n",
      "Validation Loss: 0.26776616058954933\n",
      "Validation correlation: 0.5809454987844649\n",
      "Validation r2: 0.3285656842782022\n",
      "EPOCH: 253\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23491165142507497\n",
      "Training correlation: 0.5860455058335952\n",
      "Training r2: 0.3434379172796669\n",
      "Validation Loss: 0.26546415178230853\n",
      "Validation correlation: 0.5810938773845588\n",
      "Validation r2: 0.33433803583112554\n",
      "EPOCH: 254\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23492348292341747\n",
      "Training correlation: 0.5860122291889689\n",
      "Training r2: 0.34340485577897284\n",
      "Validation Loss: 0.26584598563377326\n",
      "Validation correlation: 0.5810814987217519\n",
      "Validation r2: 0.3333805904312801\n",
      "EPOCH: 255\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23499270832898742\n",
      "Training correlation: 0.5858455696969287\n",
      "Training r2: 0.34321136576080347\n",
      "Validation Loss: 0.26488760516597687\n",
      "Validation correlation: 0.5811109624913697\n",
      "Validation r2: 0.3357837947718595\n",
      "EPOCH: 256\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23489396808567228\n",
      "Training correlation: 0.5860830023597157\n",
      "Training r2: 0.34348734998553276\n",
      "Validation Loss: 0.2649345688969761\n",
      "Validation correlation: 0.5811278742119096\n",
      "Validation r2: 0.3356660086286508\n",
      "EPOCH: 257\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23501674290070054\n",
      "Training correlation: 0.5857854415041959\n",
      "Training r2: 0.3431441981738388\n",
      "Validation Loss: 0.26578206541627725\n",
      "Validation correlation: 0.5810521887814409\n",
      "Validation r2: 0.33354086854775533\n",
      "EPOCH: 258\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23542570941216123\n",
      "Training correlation: 0.5848191903282054\n",
      "Training r2: 0.3420011626926822\n",
      "Validation Loss: 0.2644946799396123\n",
      "Validation correlation: 0.5811928823283472\n",
      "Validation r2: 0.33676904799628526\n",
      "EPOCH: 259\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23487941473040377\n",
      "Training correlation: 0.5862402617947721\n",
      "Training r2: 0.34352801882345474\n",
      "Validation Loss: 0.2642860708274527\n",
      "Validation correlation: 0.5812101386855936\n",
      "Validation r2: 0.337292151413207\n",
      "EPOCH: 260\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23510903855231538\n",
      "Training correlation: 0.5857134483272446\n",
      "Training r2: 0.3428862403844387\n",
      "Validation Loss: 0.2661690733801638\n",
      "Validation correlation: 0.5810838478045102\n",
      "Validation r2: 0.332570459672604\n",
      "EPOCH: 261\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234993982067696\n",
      "Training correlation: 0.5858760552221274\n",
      "Training r2: 0.3432078166270467\n",
      "Validation Loss: 0.2643940399141984\n",
      "Validation correlation: 0.5812237211203561\n",
      "Validation r2: 0.3370214097816201\n",
      "EPOCH: 262\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23489587438663115\n",
      "Training correlation: 0.5860804544137724\n",
      "Training r2: 0.34348201385256216\n",
      "Validation Loss: 0.26483767255981555\n",
      "Validation correlation: 0.5811954845414915\n",
      "Validation r2: 0.33590899166436494\n",
      "EPOCH: 263\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23509624086577316\n",
      "Training correlation: 0.5855973538946534\n",
      "Training r2: 0.3429220009739654\n",
      "Validation Loss: 0.2650595037828759\n",
      "Validation correlation: 0.5811616400340528\n",
      "Validation r2: 0.335352725109882\n",
      "EPOCH: 264\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23510961291045723\n",
      "Training correlation: 0.5855868534506756\n",
      "Training r2: 0.3428846365946415\n",
      "Validation Loss: 0.2647113724383487\n",
      "Validation correlation: 0.5811726940792012\n",
      "Validation r2: 0.3362256852815919\n",
      "EPOCH: 265\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23491316636160883\n",
      "Training correlation: 0.5860376649908468\n",
      "Training r2: 0.3434336816976167\n",
      "Validation Loss: 0.26456923521179815\n",
      "Validation correlation: 0.5812113830750263\n",
      "Validation r2: 0.3365820918234017\n",
      "EPOCH: 266\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23475293208085293\n",
      "Training correlation: 0.5864340003967777\n",
      "Training r2: 0.3438815288948408\n",
      "Validation Loss: 0.2672173247164184\n",
      "Validation correlation: 0.5810680368264126\n",
      "Validation r2: 0.32994191791873484\n",
      "EPOCH: 267\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350084620857879\n",
      "Training correlation: 0.5858198135983195\n",
      "Training r2: 0.34316734105032587\n",
      "Validation Loss: 0.26435472373741226\n",
      "Validation correlation: 0.5812453523905945\n",
      "Validation r2: 0.33711999571878415\n",
      "EPOCH: 268\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23506696373360675\n",
      "Training correlation: 0.5856973207347702\n",
      "Training r2: 0.34300383166225556\n",
      "Validation Loss: 0.26426890946249426\n",
      "Validation correlation: 0.5812869389341739\n",
      "Validation r2: 0.3373351771282036\n",
      "EPOCH: 269\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2351758026225486\n",
      "Training correlation: 0.5855738252433801\n",
      "Training r2: 0.34269963464718445\n",
      "Validation Loss: 0.26491202667860275\n",
      "Validation correlation: 0.5811608471070168\n",
      "Validation r2: 0.3357225281404873\n",
      "EPOCH: 270\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23513088790898212\n",
      "Training correlation: 0.5855476328453244\n",
      "Training r2: 0.34282517104061294\n",
      "Validation Loss: 0.26569637034337334\n",
      "Validation correlation: 0.5812024046303679\n",
      "Validation r2: 0.33375577508682985\n",
      "EPOCH: 271\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23480160305476022\n",
      "Training correlation: 0.5862990214769116\n",
      "Training r2: 0.34374549730583004\n",
      "Validation Loss: 0.26637728391058896\n",
      "Validation correlation: 0.5811664246814363\n",
      "Validation r2: 0.3320483415196369\n",
      "EPOCH: 272\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23500187826986024\n",
      "Training correlation: 0.5858425042645663\n",
      "Training r2: 0.3431857393829987\n",
      "Validation Loss: 0.2656137782478973\n",
      "Validation correlation: 0.58118445896073\n",
      "Validation r2: 0.333962872992407\n",
      "EPOCH: 273\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23487694478085902\n",
      "Training correlation: 0.586160313692794\n",
      "Training r2: 0.34353492254457785\n",
      "Validation Loss: 0.265104986801357\n",
      "Validation correlation: 0.581238091532901\n",
      "Validation r2: 0.3352386857414785\n",
      "EPOCH: 274\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23492752298699088\n",
      "Training correlation: 0.5860084956312548\n",
      "Training r2: 0.3433935618297065\n",
      "Validation Loss: 0.26487648585310497\n",
      "Validation correlation: 0.581252767852448\n",
      "Validation r2: 0.33581167843664295\n",
      "EPOCH: 275\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23525985470988017\n",
      "Training correlation: 0.5852069448028026\n",
      "Training r2: 0.34246471592985817\n",
      "Validation Loss: 0.265036602095929\n",
      "Validation correlation: 0.5812215484367457\n",
      "Validation r2: 0.33541014641991973\n",
      "EPOCH: 276\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348358273033256\n",
      "Training correlation: 0.5862260357347018\n",
      "Training r2: 0.34364984182248604\n",
      "Validation Loss: 0.2647456392923215\n",
      "Validation correlation: 0.5812696344843473\n",
      "Validation r2: 0.3361397597381509\n",
      "EPOCH: 277\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23488686322656607\n",
      "Training correlation: 0.5860996738917396\n",
      "Training r2: 0.34350720405859025\n",
      "Validation Loss: 0.26431378157065344\n",
      "Validation correlation: 0.5813614596961881\n",
      "Validation r2: 0.33722265725536216\n",
      "EPOCH: 278\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23475758747826053\n",
      "Training correlation: 0.5864151659777226\n",
      "Training r2: 0.34386852025919434\n",
      "Validation Loss: 0.26439189055288276\n",
      "Validation correlation: 0.5813076543228348\n",
      "Validation r2: 0.3370267934410063\n",
      "EPOCH: 279\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23518376866964294\n",
      "Training correlation: 0.5854006126039516\n",
      "Training r2: 0.34267737512609053\n",
      "Validation Loss: 0.2657009093325641\n",
      "Validation correlation: 0.5812483302881051\n",
      "Validation r2: 0.33374437084832376\n",
      "EPOCH: 280\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348231320560142\n",
      "Training correlation: 0.5862582788810387\n",
      "Training r2: 0.343685330183929\n",
      "Validation Loss: 0.26507914603975147\n",
      "Validation correlation: 0.5813043158513795\n",
      "Validation r2: 0.3353034756981015\n",
      "EPOCH: 281\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23496271551910392\n",
      "Training correlation: 0.5859156514746598\n",
      "Training r2: 0.3432952030635439\n",
      "Validation Loss: 0.2656626417609952\n",
      "Validation correlation: 0.5812622468164803\n",
      "Validation r2: 0.3338403583659054\n",
      "EPOCH: 282\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2352179456564723\n",
      "Training correlation: 0.5853057975139039\n",
      "Training r2: 0.34258185077535586\n",
      "Validation Loss: 0.26474243015059984\n",
      "Validation correlation: 0.5813450639882793\n",
      "Validation r2: 0.336147812694924\n",
      "EPOCH: 283\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23487625634266465\n",
      "Training correlation: 0.5861212708857815\n",
      "Training r2: 0.3435368424493733\n",
      "Validation Loss: 0.2650479542252346\n",
      "Validation correlation: 0.5813133544896232\n",
      "Validation r2: 0.3353816888735083\n",
      "EPOCH: 284\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23488193776209543\n",
      "Training correlation: 0.5861114714661252\n",
      "Training r2: 0.3435209726288033\n",
      "Validation Loss: 0.2645787844106414\n",
      "Validation correlation: 0.5813687778867695\n",
      "Validation r2: 0.33655816144620787\n",
      "EPOCH: 285\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23486501712932942\n",
      "Training correlation: 0.5861553738352123\n",
      "Training r2: 0.34356826312534217\n",
      "Validation Loss: 0.2653497420617419\n",
      "Validation correlation: 0.5812503244068135\n",
      "Validation r2: 0.33462492479607364\n",
      "EPOCH: 286\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23485797606192604\n",
      "Training correlation: 0.5861723757847457\n",
      "Training r2: 0.3435879398799504\n",
      "Validation Loss: 0.2682129930642308\n",
      "Validation correlation: 0.5810968595794952\n",
      "Validation r2: 0.32744523027676387\n",
      "EPOCH: 287\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23496329430075802\n",
      "Training correlation: 0.5859763021606421\n",
      "Training r2: 0.34329357666866667\n",
      "Validation Loss: 0.2641529035524584\n",
      "Validation correlation: 0.5814168727334152\n",
      "Validation r2: 0.3376260549481942\n",
      "EPOCH: 288\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23503882670351597\n",
      "Training correlation: 0.5857490159741635\n",
      "Training r2: 0.34308247206271714\n",
      "Validation Loss: 0.26669048161487735\n",
      "Validation correlation: 0.5812722663552052\n",
      "Validation r2: 0.33126299821596183\n",
      "EPOCH: 289\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23485584043678\n",
      "Training correlation: 0.5861793434880793\n",
      "Training r2: 0.34359390878873997\n",
      "Validation Loss: 0.2648099767168666\n",
      "Validation correlation: 0.5813509511892353\n",
      "Validation r2: 0.3359784285078715\n",
      "EPOCH: 290\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347571225438425\n",
      "Training correlation: 0.5864389964815735\n",
      "Training r2: 0.34386981480140333\n",
      "Validation Loss: 0.2645198315645741\n",
      "Validation correlation: 0.5814000473760352\n",
      "Validation r2: 0.33670597821101134\n",
      "EPOCH: 291\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23482392665850232\n",
      "Training correlation: 0.5862481201168277\n",
      "Training r2: 0.3436831006898743\n",
      "Validation Loss: 0.2646604880786066\n",
      "Validation correlation: 0.5813852373766807\n",
      "Validation r2: 0.3363532772491914\n",
      "EPOCH: 292\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23490503338513158\n",
      "Training correlation: 0.5860628215580344\n",
      "Training r2: 0.34345641954402395\n",
      "Validation Loss: 0.26510436471584625\n",
      "Validation correlation: 0.5813888701759159\n",
      "Validation r2: 0.3352402292575053\n",
      "EPOCH: 293\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2349179861274186\n",
      "Training correlation: 0.5860215372296134\n",
      "Training r2: 0.3434202229169624\n",
      "Validation Loss: 0.26539946233931566\n",
      "Validation correlation: 0.5813745411671029\n",
      "Validation r2: 0.33450026346299244\n",
      "EPOCH: 294\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23481423963233033\n",
      "Training correlation: 0.5862693276906832\n",
      "Training r2: 0.34371018005681375\n",
      "Validation Loss: 0.2649249861725664\n",
      "Validation correlation: 0.5813767753622068\n",
      "Validation r2: 0.33569004167249283\n",
      "EPOCH: 295\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350342474370822\n",
      "Training correlation: 0.5857627315179053\n",
      "Training r2: 0.34309526876259855\n",
      "Validation Loss: 0.26502967534139454\n",
      "Validation correlation: 0.5814237711393047\n",
      "Validation r2: 0.33542752411361165\n",
      "EPOCH: 296\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347591473483661\n",
      "Training correlation: 0.5864080106423522\n",
      "Training r2: 0.34386416263037156\n",
      "Validation Loss: 0.2646346733924416\n",
      "Validation correlation: 0.5814253678243488\n",
      "Validation r2: 0.3364180071125684\n",
      "EPOCH: 297\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23472576659373987\n",
      "Training correlation: 0.5864912658543457\n",
      "Training r2: 0.34395745976482217\n",
      "Validation Loss: 0.2644697592685526\n",
      "Validation correlation: 0.5814602543553774\n",
      "Validation r2: 0.336831535600583\n",
      "EPOCH: 298\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23509518457761364\n",
      "Training correlation: 0.5855996109874221\n",
      "Training r2: 0.3429249573522649\n",
      "Validation Loss: 0.26408953650680883\n",
      "Validation correlation: 0.5815251215559951\n",
      "Validation r2: 0.3377849657419304\n",
      "EPOCH: 299\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23489324402656359\n",
      "Training correlation: 0.5860815404391982\n",
      "Training r2: 0.34348936918479556\n",
      "Validation Loss: 0.26458703356251906\n",
      "Validation correlation: 0.5814620961049107\n",
      "Validation r2: 0.33653748429483954\n",
      "EPOCH: 300\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23491442007810415\n",
      "Training correlation: 0.5860299532223736\n",
      "Training r2: 0.3434301799362015\n",
      "Validation Loss: 0.2640897376602075\n",
      "Validation correlation: 0.5815016690090793\n",
      "Validation r2: 0.33778446052312217\n",
      "EPOCH: 301\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23493012680598502\n",
      "Training correlation: 0.5859927318182344\n",
      "Training r2: 0.34338628341017463\n",
      "Validation Loss: 0.2647718544227523\n",
      "Validation correlation: 0.58145933349808\n",
      "Validation r2: 0.3360740254851585\n",
      "EPOCH: 302\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347999232841913\n",
      "Training correlation: 0.5863148967340286\n",
      "Training r2: 0.34375019116062555\n",
      "Validation Loss: 0.2643902980884765\n",
      "Validation correlation: 0.5815049843894631\n",
      "Validation r2: 0.3370307874589267\n",
      "EPOCH: 303\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23468586348672446\n",
      "Training correlation: 0.5865848831916864\n",
      "Training r2: 0.3440689805740348\n",
      "Validation Loss: 0.2672298055397944\n",
      "Validation correlation: 0.5813585856085515\n",
      "Validation r2: 0.3299106055677248\n",
      "EPOCH: 304\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23492373599488087\n",
      "Training correlation: 0.5860093067513406\n",
      "Training r2: 0.3434041460932187\n",
      "Validation Loss: 0.26576930707571234\n",
      "Validation correlation: 0.5814402360640505\n",
      "Validation r2: 0.3335728702337615\n",
      "EPOCH: 305\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23535697152420337\n",
      "Training correlation: 0.5849851999318423\n",
      "Training r2: 0.34219328215796097\n",
      "Validation Loss: 0.267903131153804\n",
      "Validation correlation: 0.58118879588637\n",
      "Validation r2: 0.328222220676766\n",
      "EPOCH: 306\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234878411990024\n",
      "Training correlation: 0.5861377630900269\n",
      "Training r2: 0.34353081955889475\n",
      "Validation Loss: 0.26423726132776737\n",
      "Validation correlation: 0.5815585473912017\n",
      "Validation r2: 0.33741453349844774\n",
      "EPOCH: 307\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23469352291457565\n",
      "Training correlation: 0.586561162154256\n",
      "Training r2: 0.34404757606319303\n",
      "Validation Loss: 0.26487649516576234\n",
      "Validation correlation: 0.5814661552975804\n",
      "Validation r2: 0.3358116126138624\n",
      "EPOCH: 308\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23473951906047655\n",
      "Training correlation: 0.5865344975717328\n",
      "Training r2: 0.3439190175232344\n",
      "Validation Loss: 0.26698700221238936\n",
      "Validation correlation: 0.5810961793198873\n",
      "Validation r2: 0.3305194579860228\n",
      "EPOCH: 309\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23510717602084605\n",
      "Training correlation: 0.5856104679252712\n",
      "Training r2: 0.3428914394344912\n",
      "Validation Loss: 0.267184099017537\n",
      "Validation correlation: 0.581381451710355\n",
      "Validation r2: 0.3300252132246202\n",
      "EPOCH: 310\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23463142704665388\n",
      "Training correlation: 0.5867188810581321\n",
      "Training r2: 0.34422112859223586\n",
      "Validation Loss: 0.2645054882097288\n",
      "Validation correlation: 0.5815487785440354\n",
      "Validation r2: 0.33674196172195314\n",
      "EPOCH: 311\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23482231533596493\n",
      "Training correlation: 0.586252821526638\n",
      "Training r2: 0.34368761063182773\n",
      "Validation Loss: 0.26418135558318395\n",
      "Validation correlation: 0.5815635647301431\n",
      "Validation r2: 0.3375547276624321\n",
      "EPOCH: 312\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348614189513471\n",
      "Training correlation: 0.5861642055259015\n",
      "Training r2: 0.34357831388285576\n",
      "Validation Loss: 0.2651755990944223\n",
      "Validation correlation: 0.5814915168243613\n",
      "Validation r2: 0.33506160392154793\n",
      "EPOCH: 313\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23506995542477935\n",
      "Training correlation: 0.5856695406937246\n",
      "Training r2: 0.34299546793031255\n",
      "Validation Loss: 0.2654856640207793\n",
      "Validation correlation: 0.5814514374848778\n",
      "Validation r2: 0.3342841148398421\n",
      "EPOCH: 314\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23476989555184274\n",
      "Training correlation: 0.5863819065157116\n",
      "Training r2: 0.34383411684504317\n",
      "Validation Loss: 0.2655447919448047\n",
      "Validation correlation: 0.5815114410592686\n",
      "Validation r2: 0.3341358515724716\n",
      "EPOCH: 315\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348055667545434\n",
      "Training correlation: 0.5863194170333074\n",
      "Training r2: 0.34373441535144134\n",
      "Validation Loss: 0.2651294269392976\n",
      "Validation correlation: 0.5814940592121653\n",
      "Validation r2: 0.3351774067399148\n",
      "EPOCH: 316\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23473137770260766\n",
      "Training correlation: 0.5864673940308096\n",
      "Training r2: 0.3439417684138786\n",
      "Validation Loss: 0.26513948647176344\n",
      "Validation correlation: 0.5815339257859486\n",
      "Validation r2: 0.33515216919460333\n",
      "EPOCH: 317\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348620647841341\n",
      "Training correlation: 0.5861733386916447\n",
      "Training r2: 0.3435765155185928\n",
      "Validation Loss: 0.2658726868849176\n",
      "Validation correlation: 0.5815159522879987\n",
      "Validation r2: 0.3333136377073699\n",
      "EPOCH: 318\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234676357126105\n",
      "Training correlation: 0.5866251758117096\n",
      "Training r2: 0.34409555444530515\n",
      "Validation Loss: 0.26463393396744833\n",
      "Validation correlation: 0.5815566259504457\n",
      "Validation r2: 0.3364198735535493\n",
      "EPOCH: 319\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347918529353347\n",
      "Training correlation: 0.5863277535661511\n",
      "Training r2: 0.3437727531162408\n",
      "Validation Loss: 0.26489906159704474\n",
      "Validation correlation: 0.5814923010061719\n",
      "Validation r2: 0.3357550489166288\n",
      "EPOCH: 320\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2346923052846276\n",
      "Training correlation: 0.5866008776131195\n",
      "Training r2: 0.3440509790538697\n",
      "Validation Loss: 0.26440705714663754\n",
      "Validation correlation: 0.5816417065910133\n",
      "Validation r2: 0.3369887681047742\n",
      "EPOCH: 321\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347311954073401\n",
      "Training correlation: 0.5865059670561572\n",
      "Training r2: 0.34394227711416214\n",
      "Validation Loss: 0.26404694599969963\n",
      "Validation correlation: 0.5816730820897502\n",
      "Validation r2: 0.3378917558638418\n",
      "EPOCH: 322\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23473687054072714\n",
      "Training correlation: 0.5865281869143644\n",
      "Training r2: 0.34392641972427007\n",
      "Validation Loss: 0.2653746459700183\n",
      "Validation correlation: 0.581579212274085\n",
      "Validation r2: 0.334562490558973\n",
      "EPOCH: 323\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23459302420873704\n",
      "Training correlation: 0.5867995931605902\n",
      "Training r2: 0.34432846116516036\n",
      "Validation Loss: 0.26440288507614623\n",
      "Validation correlation: 0.5816096012681171\n",
      "Validation r2: 0.33699924361714895\n",
      "EPOCH: 324\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23471057974495538\n",
      "Training correlation: 0.5865292393664421\n",
      "Training r2: 0.34399990730560737\n",
      "Validation Loss: 0.26441716510492164\n",
      "Validation correlation: 0.5816636960552071\n",
      "Validation r2: 0.3369634276781521\n",
      "EPOCH: 325\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23489778580955153\n",
      "Training correlation: 0.5861171405486922\n",
      "Training r2: 0.3434766765061268\n",
      "Validation Loss: 0.2647828563961417\n",
      "Validation correlation: 0.5816051867095503\n",
      "Validation r2: 0.33604642453205613\n",
      "EPOCH: 326\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23457388949168684\n",
      "Training correlation: 0.5870047334527192\n",
      "Training r2: 0.34438194415615686\n",
      "Validation Loss: 0.26408341436586913\n",
      "Validation correlation: 0.581656628532771\n",
      "Validation r2: 0.33780031999561877\n",
      "EPOCH: 327\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347755043325462\n",
      "Training correlation: 0.5864569580140138\n",
      "Training r2: 0.34381844063575484\n",
      "Validation Loss: 0.2655838287418704\n",
      "Validation correlation: 0.5816070242424629\n",
      "Validation r2: 0.33403795893772625\n",
      "EPOCH: 328\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23466653623048364\n",
      "Training correlation: 0.5866860643477769\n",
      "Training r2: 0.34412300389713724\n",
      "Validation Loss: 0.26685530074966146\n",
      "Validation correlation: 0.581498742874426\n",
      "Validation r2: 0.3308497111518359\n",
      "EPOCH: 329\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23490023131337076\n",
      "Training correlation: 0.5861219323274234\n",
      "Training r2: 0.34346984235220845\n",
      "Validation Loss: 0.26536398297735636\n",
      "Validation correlation: 0.5816648724399722\n",
      "Validation r2: 0.3345892424169592\n",
      "EPOCH: 330\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348578880573141\n",
      "Training correlation: 0.5861733216554808\n",
      "Training r2: 0.3435881838022794\n",
      "Validation Loss: 0.26487055927796954\n",
      "Validation correlation: 0.5816936623910209\n",
      "Validation r2: 0.3358265089104683\n",
      "EPOCH: 331\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23448219450647087\n",
      "Training correlation: 0.5870974708529206\n",
      "Training r2: 0.34463822025692803\n",
      "Validation Loss: 0.2662014777026673\n",
      "Validation correlation: 0.5815401364667278\n",
      "Validation r2: 0.332489189298107\n",
      "EPOCH: 332\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23484410043529597\n",
      "Training correlation: 0.5863191530443985\n",
      "Training r2: 0.3436267207385052\n",
      "Validation Loss: 0.2640545972789756\n",
      "Validation correlation: 0.5817594785954323\n",
      "Validation r2: 0.33787258126200936\n",
      "EPOCH: 333\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347769233487094\n",
      "Training correlation: 0.586477164228371\n",
      "Training r2: 0.3438144752380998\n",
      "Validation Loss: 0.26541107708555844\n",
      "Validation correlation: 0.581648693502619\n",
      "Validation r2: 0.33447114929514377\n",
      "EPOCH: 334\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23476774758742575\n",
      "Training correlation: 0.5863814393592282\n",
      "Training r2: 0.3438401260956173\n",
      "Validation Loss: 0.26479295131670544\n",
      "Validation correlation: 0.5817229114682788\n",
      "Validation r2: 0.33602110815736963\n",
      "EPOCH: 335\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347761522606811\n",
      "Training correlation: 0.5863588193840535\n",
      "Training r2: 0.34381663001219354\n",
      "Validation Loss: 0.26745070177205715\n",
      "Validation correlation: 0.5815691775026275\n",
      "Validation r2: 0.32935670454511\n",
      "EPOCH: 336\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23490259765960256\n",
      "Training correlation: 0.5860820284655217\n",
      "Training r2: 0.34346322809523777\n",
      "Validation Loss: 0.2653099472143681\n",
      "Validation correlation: 0.5816846759938334\n",
      "Validation r2: 0.33472473243428624\n",
      "EPOCH: 337\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23468770902259414\n",
      "Training correlation: 0.5865721217330422\n",
      "Training r2: 0.3440638259773281\n",
      "Validation Loss: 0.2644131681123884\n",
      "Validation correlation: 0.5817492104784892\n",
      "Validation r2: 0.33697344354187864\n",
      "EPOCH: 338\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234713839873476\n",
      "Training correlation: 0.5865150378913224\n",
      "Training r2: 0.34399078525159144\n",
      "Validation Loss: 0.2640141952463429\n",
      "Validation correlation: 0.5818509634699076\n",
      "Validation r2: 0.33797388815539364\n",
      "EPOCH: 339\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23468757026399967\n",
      "Training correlation: 0.5865943630050483\n",
      "Training r2: 0.34406421121618935\n",
      "Validation Loss: 0.264837341029214\n",
      "Validation correlation: 0.5817437687018481\n",
      "Validation r2: 0.3359098048129552\n",
      "EPOCH: 340\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23462696209308903\n",
      "Training correlation: 0.5867206232111006\n",
      "Training r2: 0.3442336046237936\n",
      "Validation Loss: 0.2642444395240502\n",
      "Validation correlation: 0.5817042344469376\n",
      "Validation r2: 0.33739653262820357\n",
      "EPOCH: 341\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23493845441700084\n",
      "Training correlation: 0.5859718675775878\n",
      "Training r2: 0.34336301462584873\n",
      "Validation Loss: 0.2647046319369612\n",
      "Validation correlation: 0.5817013332979575\n",
      "Validation r2: 0.33624259659779876\n",
      "EPOCH: 342\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23469563921595768\n",
      "Training correlation: 0.5865609985940287\n",
      "Training r2: 0.3440416571541939\n",
      "Validation Loss: 0.264362361978968\n",
      "Validation correlation: 0.5818189096924887\n",
      "Validation r2: 0.3371008363077539\n",
      "EPOCH: 343\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347874438577139\n",
      "Training correlation: 0.5863518497008111\n",
      "Training r2: 0.34378507046663764\n",
      "Validation Loss: 0.26419366505366476\n",
      "Validation correlation: 0.5818398743739344\n",
      "Validation r2: 0.3375238512217569\n",
      "EPOCH: 344\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23478727948931175\n",
      "Training correlation: 0.5863353532242377\n",
      "Training r2: 0.34378552634795634\n",
      "Validation Loss: 0.26677941935506944\n",
      "Validation correlation: 0.5816817477520577\n",
      "Validation r2: 0.3310399596303655\n",
      "EPOCH: 345\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23495193914483878\n",
      "Training correlation: 0.5859428759657563\n",
      "Training r2: 0.34332531628015206\n",
      "Validation Loss: 0.2644517318264609\n",
      "Validation correlation: 0.5817652877356662\n",
      "Validation r2: 0.33687674562860204\n",
      "EPOCH: 346\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23450999465118214\n",
      "Training correlation: 0.5869955446448807\n",
      "Training r2: 0.34456052606829335\n",
      "Validation Loss: 0.2659881005099462\n",
      "Validation correlation: 0.5817421676688199\n",
      "Validation r2: 0.3330242405760909\n",
      "EPOCH: 347\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23488378213388295\n",
      "Training correlation: 0.5861105323620011\n",
      "Training r2: 0.3435158186896967\n",
      "Validation Loss: 0.2645433236739968\n",
      "Validation correlation: 0.5818250111590408\n",
      "Validation r2: 0.3366470726581263\n",
      "EPOCH: 348\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23453584705360933\n",
      "Training correlation: 0.5869464280398273\n",
      "Training r2: 0.34448827254801695\n",
      "Validation Loss: 0.26852088069130015\n",
      "Validation correlation: 0.5816388788843279\n",
      "Validation r2: 0.3266731959223469\n",
      "EPOCH: 349\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23497877426543248\n",
      "Training correlation: 0.5858974401928401\n",
      "Training r2: 0.3432503220276508\n",
      "Validation Loss: 0.2665773142028008\n",
      "Validation correlation: 0.5817662674351525\n",
      "Validation r2: 0.33154676166703523\n",
      "EPOCH: 350\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23524037798548894\n",
      "Training correlation: 0.5852539236445244\n",
      "Training r2: 0.342519150832171\n",
      "Validation Loss: 0.2648034597192554\n",
      "Validation correlation: 0.5818293825038519\n",
      "Validation r2: 0.33599478910198477\n",
      "EPOCH: 351\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2348494442708979\n",
      "Training correlation: 0.5862580273373457\n",
      "Training r2: 0.3436117912244141\n",
      "Validation Loss: 0.26447161993749047\n",
      "Validation correlation: 0.5818501474597149\n",
      "Validation r2: 0.3368268731301579\n",
      "EPOCH: 352\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347927893230309\n",
      "Training correlation: 0.5864087508097545\n",
      "Training r2: 0.34377012583395283\n",
      "Validation Loss: 0.26824950985621854\n",
      "Validation correlation: 0.5816752687740809\n",
      "Validation r2: 0.32735367169164964\n",
      "EPOCH: 353\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2346194151155753\n",
      "Training correlation: 0.5867812384012383\n",
      "Training r2: 0.3442547055411661\n",
      "Validation Loss: 0.26392940163867007\n",
      "Validation correlation: 0.5819637810468492\n",
      "Validation r2: 0.3381865094475457\n",
      "EPOCH: 354\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23469163966244375\n",
      "Training correlation: 0.5865612274392737\n",
      "Training r2: 0.3440528376110167\n",
      "Validation Loss: 0.26420508237157175\n",
      "Validation correlation: 0.5818306483077806\n",
      "Validation r2: 0.33749523834232276\n",
      "EPOCH: 355\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23462681635000154\n",
      "Training correlation: 0.5867176681997449\n",
      "Training r2: 0.3442340150661165\n",
      "Validation Loss: 0.2641416985631389\n",
      "Validation correlation: 0.5817872289840695\n",
      "Validation r2: 0.33765416307092677\n",
      "EPOCH: 356\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23473163636166547\n",
      "Training correlation: 0.5864696965772278\n",
      "Training r2: 0.34394105466501534\n",
      "Validation Loss: 0.26473559093504445\n",
      "Validation correlation: 0.58187936360737\n",
      "Validation r2: 0.33616495217095455\n",
      "EPOCH: 357\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23465467143939114\n",
      "Training correlation: 0.5866698056423537\n",
      "Training r2: 0.34415616341959987\n",
      "Validation Loss: 0.2643699164066076\n",
      "Validation correlation: 0.5819182543164136\n",
      "Validation r2: 0.33708190092883106\n",
      "EPOCH: 358\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23487039542176355\n",
      "Training correlation: 0.5861346118308568\n",
      "Training r2: 0.34355322633818874\n",
      "Validation Loss: 0.2659178216100139\n",
      "Validation correlation: 0.5818202360138748\n",
      "Validation r2: 0.33320046409348636\n",
      "EPOCH: 359\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23450354028119158\n",
      "Training correlation: 0.5870248037514277\n",
      "Training r2: 0.3445785642511918\n",
      "Validation Loss: 0.2648567821326909\n",
      "Validation correlation: 0.5818339969944103\n",
      "Validation r2: 0.33586105681205614\n",
      "EPOCH: 360\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23480922383508343\n",
      "Training correlation: 0.5862931998538379\n",
      "Training r2: 0.3437241997200047\n",
      "Validation Loss: 0.26496202074830255\n",
      "Validation correlation: 0.5819114473384501\n",
      "Validation r2: 0.3355971712755056\n",
      "EPOCH: 361\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23451760099688646\n",
      "Training correlation: 0.5869966779412525\n",
      "Training r2: 0.3445392594792368\n",
      "Validation Loss: 0.26546217563641955\n",
      "Validation correlation: 0.581883830290618\n",
      "Validation r2: 0.33434300747065315\n",
      "EPOCH: 362\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23470156602390954\n",
      "Training correlation: 0.5865475896029675\n",
      "Training r2: 0.344025092446009\n",
      "Validation Loss: 0.2667406880131647\n",
      "Validation correlation: 0.5818282429164555\n",
      "Validation r2: 0.3311370823111097\n",
      "EPOCH: 363\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23459038802825863\n",
      "Training correlation: 0.5868089399112906\n",
      "Training r2: 0.34433582622441405\n",
      "Validation Loss: 0.2642672797474586\n",
      "Validation correlation: 0.581968886709301\n",
      "Validation r2: 0.3373392718727377\n",
      "EPOCH: 364\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23464165327568626\n",
      "Training correlation: 0.5866854346461623\n",
      "Training r2: 0.3441925449757691\n",
      "Validation Loss: 0.2648082874008239\n",
      "Validation correlation: 0.5819240163914028\n",
      "Validation r2: 0.33598265571518293\n",
      "EPOCH: 365\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23461979716734294\n",
      "Training correlation: 0.5867327666711668\n",
      "Training r2: 0.34425363713082446\n",
      "Validation Loss: 0.2642729455681883\n",
      "Validation correlation: 0.5819708747839649\n",
      "Validation r2: 0.3373250596294889\n",
      "EPOCH: 366\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2346011192361356\n",
      "Training correlation: 0.5867767798147518\n",
      "Training r2: 0.3443058355609273\n",
      "Validation Loss: 0.2652975855930062\n",
      "Validation correlation: 0.5818626954398649\n",
      "Validation r2: 0.3347557469890655\n",
      "EPOCH: 367\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2345393379032157\n",
      "Training correlation: 0.5869491942450928\n",
      "Training r2: 0.3444785144453011\n",
      "Validation Loss: 0.26562285808881025\n",
      "Validation correlation: 0.5817514071168788\n",
      "Validation r2: 0.33394010410463815\n",
      "EPOCH: 368\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23468097271190244\n",
      "Training correlation: 0.5865865030319858\n",
      "Training r2: 0.34408265481820743\n",
      "Validation Loss: 0.2666353339206019\n",
      "Validation correlation: 0.5818426060119275\n",
      "Validation r2: 0.3314012665298125\n",
      "EPOCH: 369\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23447053831890294\n",
      "Training correlation: 0.5871037441660183\n",
      "Training r2: 0.34467079992838157\n",
      "Validation Loss: 0.26548723972240235\n",
      "Validation correlation: 0.5818908531788407\n",
      "Validation r2: 0.33428017194296933\n",
      "EPOCH: 370\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23461448755575673\n",
      "Training correlation: 0.5867516620449917\n",
      "Training r2: 0.3442684822759654\n",
      "Validation Loss: 0.2655722754591662\n",
      "Validation correlation: 0.5819078190176475\n",
      "Validation r2: 0.33406694448080265\n",
      "EPOCH: 371\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2345150442068119\n",
      "Training correlation: 0.5869880133779929\n",
      "Training r2: 0.3445464135846442\n",
      "Validation Loss: 0.2653222045339678\n",
      "Validation correlation: 0.5817736139189748\n",
      "Validation r2: 0.3346939866672849\n",
      "EPOCH: 372\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23496944973444772\n",
      "Training correlation: 0.5859762036860199\n",
      "Training r2: 0.34327636895388947\n",
      "Validation Loss: 0.2643466142753948\n",
      "Validation correlation: 0.5819605437593219\n",
      "Validation r2: 0.3371403252546803\n",
      "EPOCH: 373\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23483613601791667\n",
      "Training correlation: 0.5862480332899096\n",
      "Training r2: 0.3436489802113504\n",
      "Validation Loss: 0.26428555118117275\n",
      "Validation correlation: 0.5820480162211763\n",
      "Validation r2: 0.3372934463035844\n",
      "EPOCH: 374\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23490489299682207\n",
      "Training correlation: 0.5860594291136778\n",
      "Training r2: 0.34345680947308954\n",
      "Validation Loss: 0.26410150513403075\n",
      "Validation correlation: 0.5820125720591512\n",
      "Validation r2: 0.33775496053062914\n",
      "EPOCH: 375\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23458656192298774\n",
      "Training correlation: 0.5868151535391863\n",
      "Training r2: 0.3443465237037783\n",
      "Validation Loss: 0.2648784992496233\n",
      "Validation correlation: 0.5819594211384568\n",
      "Validation r2: 0.3358066129329528\n",
      "EPOCH: 376\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23481866896498083\n",
      "Training correlation: 0.5863306847106098\n",
      "Training r2: 0.3436977999903764\n",
      "Validation Loss: 0.2639080980037239\n",
      "Validation correlation: 0.5820558229042507\n",
      "Validation r2: 0.33823993697308197\n",
      "EPOCH: 377\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2350515822502837\n",
      "Training correlation: 0.5857357845827921\n",
      "Training r2: 0.3430468201631446\n",
      "Validation Loss: 0.26498027914429645\n",
      "Validation correlation: 0.5819716900947717\n",
      "Validation r2: 0.3355513829196639\n",
      "EPOCH: 378\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23481554456844103\n",
      "Training correlation: 0.5862652680321302\n",
      "Training r2: 0.34370653367631254\n",
      "Validation Loss: 0.2667418651330533\n",
      "Validation correlation: 0.5819137014723882\n",
      "Validation r2: 0.3311341371883879\n",
      "EPOCH: 379\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2349632535578821\n",
      "Training correlation: 0.5859159771043945\n",
      "Training r2: 0.3432936943975906\n",
      "Validation Loss: 0.26396283594107606\n",
      "Validation correlation: 0.581969948743786\n",
      "Validation r2: 0.3381026600092144\n",
      "EPOCH: 380\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23472877993684083\n",
      "Training correlation: 0.5864734311969799\n",
      "Training r2: 0.3439490331925551\n",
      "Validation Loss: 0.2638338947499857\n",
      "Validation correlation: 0.5821467344780897\n",
      "Validation r2: 0.33842597763094573\n",
      "EPOCH: 381\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23476114374928478\n",
      "Training correlation: 0.586417759931602\n",
      "Training r2: 0.34385858237304656\n",
      "Validation Loss: 0.2674860917325059\n",
      "Validation correlation: 0.5818794900268485\n",
      "Validation r2: 0.3292679638829187\n",
      "EPOCH: 382\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2347334879507624\n",
      "Training correlation: 0.586474345437241\n",
      "Training r2: 0.3439358803279339\n",
      "Validation Loss: 0.2649840526330533\n",
      "Validation correlation: 0.5820908156012048\n",
      "Validation r2: 0.3355419441601861\n",
      "EPOCH: 383\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23473143637234894\n",
      "Training correlation: 0.5864686766138123\n",
      "Training r2: 0.3439416062402507\n",
      "Validation Loss: 0.26476300553574156\n",
      "Validation correlation: 0.5820723638511569\n",
      "Validation r2: 0.33609621339784435\n",
      "EPOCH: 384\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23444851970468894\n",
      "Training correlation: 0.5871632932066265\n",
      "Training r2: 0.34473233963963523\n",
      "Validation Loss: 0.2654051598230804\n",
      "Validation correlation: 0.5820143387471239\n",
      "Validation r2: 0.3344859768036741\n",
      "EPOCH: 385\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23485636706755297\n",
      "Training correlation: 0.5861699902721089\n",
      "Training r2: 0.3435924314226163\n",
      "Validation Loss: 0.2651896425817011\n",
      "Validation correlation: 0.5820330974512973\n",
      "Validation r2: 0.3350264046107907\n",
      "EPOCH: 386\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23464448222817172\n",
      "Training correlation: 0.5866768996989551\n",
      "Training r2: 0.34418463536991406\n",
      "Validation Loss: 0.26573392084032654\n",
      "Validation correlation: 0.5820520711006487\n",
      "Validation r2: 0.3336616070126083\n",
      "EPOCH: 387\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23471782499237107\n",
      "Training correlation: 0.5865036951778437\n",
      "Training r2: 0.3439796509470583\n",
      "Validation Loss: 0.2665010137386281\n",
      "Validation correlation: 0.581973339909453\n",
      "Validation r2: 0.3317380862105084\n",
      "EPOCH: 388\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23486846118283264\n",
      "Training correlation: 0.5861440413362755\n",
      "Training r2: 0.3435586370531798\n",
      "Validation Loss: 0.26696440598060345\n",
      "Validation correlation: 0.5818987656811948\n",
      "Validation r2: 0.33057610453165087\n",
      "EPOCH: 389\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23461565187074152\n",
      "Training correlation: 0.5867721013362395\n",
      "Training r2: 0.3442652201624079\n",
      "Validation Loss: 0.26400027096107814\n",
      "Validation correlation: 0.582170753525796\n",
      "Validation r2: 0.33800880348445195\n",
      "EPOCH: 390\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2345184368078833\n",
      "Training correlation: 0.5869792969051754\n",
      "Training r2: 0.344536925470864\n",
      "Validation Loss: 0.2660412348077033\n",
      "Validation correlation: 0.5820567609954463\n",
      "Validation r2: 0.33289102465997644\n",
      "EPOCH: 391\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23465849381959908\n",
      "Training correlation: 0.5866439776785642\n",
      "Training r2: 0.34414548004129764\n",
      "Validation Loss: 0.2652520224856719\n",
      "Validation correlation: 0.5819513820000428\n",
      "Validation r2: 0.33486997963079357\n",
      "EPOCH: 392\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234574385623507\n",
      "Training correlation: 0.58686039267655\n",
      "Training r2: 0.3443805537156813\n",
      "Validation Loss: 0.26497690237474253\n",
      "Validation correlation: 0.5820982299078534\n",
      "Validation r2: 0.33555984992474264\n",
      "EPOCH: 393\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23459100033547917\n",
      "Training correlation: 0.5868101940906615\n",
      "Training r2: 0.34433411982319306\n",
      "Validation Loss: 0.26447165160052544\n",
      "Validation correlation: 0.5821498316575304\n",
      "Validation r2: 0.3368267806970323\n",
      "EPOCH: 394\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.234884404917843\n",
      "Training correlation: 0.5861009715830245\n",
      "Training r2: 0.3435140707495993\n",
      "Validation Loss: 0.26542362868513025\n",
      "Validation correlation: 0.5820964183488897\n",
      "Validation r2: 0.33443967356383686\n",
      "EPOCH: 395\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23521872442744293\n",
      "Training correlation: 0.5853035942271096\n",
      "Training r2: 0.3425796701330277\n",
      "Validation Loss: 0.26395947220924243\n",
      "Validation correlation: 0.5821680705196779\n",
      "Validation r2: 0.3381110905201079\n",
      "EPOCH: 396\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23467723577532565\n",
      "Training correlation: 0.5865966846161925\n",
      "Training r2: 0.34409309423965584\n",
      "Validation Loss: 0.26450449361792416\n",
      "Validation correlation: 0.5821728395461588\n",
      "Validation r2: 0.33674444430706496\n",
      "EPOCH: 397\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23452783444322825\n",
      "Training correlation: 0.5869598338306606\n",
      "Training r2: 0.3445106593166376\n",
      "Validation Loss: 0.2640416936609561\n",
      "Validation correlation: 0.582194680983658\n",
      "Validation r2: 0.3379049405559713\n",
      "EPOCH: 398\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23450895931650162\n",
      "Training correlation: 0.5869968516180941\n",
      "Training r2: 0.3445634171843758\n",
      "Validation Loss: 0.2647736722534664\n",
      "Validation correlation: 0.5821329605339524\n",
      "Validation r2: 0.3360694819004505\n",
      "EPOCH: 399\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.2344302296456601\n",
      "Training correlation: 0.5872425649005155\n",
      "Training r2: 0.34478345897930407\n",
      "Validation Loss: 0.2657592047050227\n",
      "Validation correlation: 0.5820893583459279\n",
      "Validation r2: 0.3335981968662667\n",
      "EPOCH: 400\n",
      "Training...\n",
      "Validating..\n",
      "Training Loss: 0.23475051661035365\n",
      "Training correlation: 0.5865414449055683\n",
      "Training r2: 0.34388827920588827\n",
      "Validation Loss: 0.26411261140918235\n",
      "Validation correlation: 0.5822077810825461\n",
      "Validation r2: 0.3377271036223177\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "seed_everything(seed)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "loss = nn.MSELoss(reduction='none')\n",
    "scheduler = StepLR(optimizer, step_size=10, gamma=0.3)\n",
    "train_loss = []\n",
    "val_loss = []\n",
    "\n",
    "train_r2 = []\n",
    "val_r2 = []\n",
    "\n",
    "train_correlation = []\n",
    "val_correlation = []\n",
    "\n",
    "for epoch in range(400):\n",
    "    print('EPOCH:', epoch+1)\n",
    "    print('Training...')\n",
    "    loss_value, correlation, r2_value = train(model, train_dataloader, optimizer, loss)\n",
    "    train_loss.append(loss_value)\n",
    "    train_correlation.append(correlation)\n",
    "    train_r2.append(r2_value)\n",
    "\n",
    "    print('Validating..')\n",
    "    loss_value, correlation, r2_value = validate(model, val_dataloader, loss)\n",
    "    val_loss.append(loss_value)\n",
    "    val_correlation.append(correlation)\n",
    "    val_r2.append(r2_value)\n",
    "\n",
    "    scheduler.step(loss_value)\n",
    "\n",
    "\n",
    "    print('Training Loss:', train_loss[-1])\n",
    "    print('Training correlation:', train_correlation[-1])\n",
    "    print('Training r2:', train_r2[-1])\n",
    "\n",
    "    print('Validation Loss:', val_loss[-1])\n",
    "    print('Validation correlation:', val_correlation[-1])\n",
    "    print('Validation r2:', val_r2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9064b0b7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T01:14:38.465801Z",
     "iopub.status.busy": "2023-04-12T01:14:38.464809Z",
     "iopub.status.idle": "2023-04-12T01:14:38.479096Z",
     "shell.execute_reply": "2023-04-12T01:14:38.478100Z"
    },
    "papermill": {
     "duration": 0.067795,
     "end_time": "2023-04-12T01:14:38.481353",
     "exception": false,
     "start_time": "2023-04-12T01:14:38.413558",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e6066d62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T01:14:38.583788Z",
     "iopub.status.busy": "2023-04-12T01:14:38.582798Z",
     "iopub.status.idle": "2023-04-12T01:14:38.588100Z",
     "shell.execute_reply": "2023-04-12T01:14:38.587008Z"
    },
    "papermill": {
     "duration": 0.058617,
     "end_time": "2023-04-12T01:14:38.590200",
     "exception": false,
     "start_time": "2023-04-12T01:14:38.531583",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_dict = {\n",
    "    'train_loss': train_loss,\n",
    "    'validation_loss': val_loss,\n",
    "    'train_correlation': train_correlation,\n",
    "    'validation_correlation': val_correlation,\n",
    "    'train_r2': train_r2,\n",
    "    'validation_r2': val_r2\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92b50299",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-04-12T01:14:38.692761Z",
     "iopub.status.busy": "2023-04-12T01:14:38.692184Z",
     "iopub.status.idle": "2023-04-12T01:14:38.702402Z",
     "shell.execute_reply": "2023-04-12T01:14:38.701509Z"
    },
    "papermill": {
     "duration": 0.064338,
     "end_time": "2023-04-12T01:14:38.704545",
     "exception": false,
     "start_time": "2023-04-12T01:14:38.640207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('results.json', 'w') as f:\n",
    "    json.dump(results_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7795016c",
   "metadata": {
    "papermill": {
     "duration": 0.049324,
     "end_time": "2023-04-12T01:14:38.803737",
     "exception": false,
     "start_time": "2023-04-12T01:14:38.754413",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15306.33219,
   "end_time": "2023-04-12T01:14:42.688181",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-04-11T20:59:36.355991",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
